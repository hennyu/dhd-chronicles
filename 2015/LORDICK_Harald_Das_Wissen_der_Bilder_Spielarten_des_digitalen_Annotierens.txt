DHd2015 Graz ∙ Sektion „Das Wissen der Bilder. Spielarten des digitalen Annotierens“ ∙ Abstract zur übergeordneten
Fragestellung der Sektion

___________________________________________________________________________

Das Wissen der Bilder. Spielarten des digitalen Annotierens
Harald Lordick, Salomon-Ludwig-Steinheim-Institut für deutsch-jüdische Geschichte, Essen
Stefan Schmunk, SUB Göttingen (DARIAH-DE)
Sibylle Söring, SUB Göttingen (TextGrid)

Das Annotieren als eine Form spontanen und/oder systematischen Kommentierens und Explizierens ist
traditionell ein fester Bestandteil geistes- und kulturwissenschaftlichen Arbeitens. Nicht nur ihre
prominenteste Spielart, die Fußnote, erfährt dabei im digitalen Medium einen radikalen Wandel.
Annotiert, kommentiert, erläutert, verwiesen, ergänzt, vermerkt, aber auch strukturiert, geordnet, (re)organisiert werden jenseits der Gutenberg-Galaxis nicht mehr nur Texte, sondern auch Bilder und
audiovisuelle Medien, öffnen sich neue, auch kollaborative Wissensräume jenseits der linearen Struktur,
die die gedruckte Annotation vorgab. Zudem entstehen - z.B. durch algorithmische Verarbeitungen wie
etwa die automatisierte Mustererkennung - neue, nicht mehr ausschließlich manuell erzeugte Annotate,
die wiederum neues Wissen generieren. In digitaler Form in den von John Unsworth aufgestellten
“Scholarly Primitives” dokumentiert, hat das Annotieren als geisteswissenschaftliche Praxis und Methode
mit der Überführung von Forschungsgegenständen in digitale Formate und dem Generieren genuin
digitalen Materials (born digital) nicht zuletzt auch im Zuge der Entwicklungen im Bereich der Linked Open
Data disziplinübergreifend noch an Relevanz für die Digital Humanities gewonnen. Zeitgemäßes
Annotatieren verspricht Eigenschaften wie punktgenaue Referenzierung oder bidirektionale Verknüpfung
(backlink). Initiativen wie Open Annotation, annotatorjs.org oder Hypothes.is sehen dies Thema im
Zentrum künftiger Webentwicklungen.
Annotationen in ihrem digitalen Lebenszyklus 'einzufangen', ihnen einen Ort zu bieten, an dem sie
methodisch angemessen erschaffen werden können, kontrolliert erreichbar bleiben und nachhaltig
gespeichert werden, ist auch deshalb eine Herausforderung, weil die vielfältige Motivation, die
Zielsetzung des annotierenden Forschers, der Grund der Annotation höchst relevant sind für den Entwurf
und die konkrekte Implementation von Annotationssystemen, die im Ergebnis infrastruktureller
Unterstützung bedürfen.
Die Sektion “Das Wissen der Bilder. Spielarten des digitalen Annotierens“ hat das Ziel, anhand der
Virtuellen Forschungsinfrastrukturen TextGrid und DARIAH-DE aufzuzeigen, dass Werkzeuge und Services
des digitalen Annotierens, die im Rahmen einer Digitalen Forschungsumgebung entwickelt bzw.
eingesetzt werden und in einer digitalen Forschungsinfrastruktur implementiert sind, genutzt werden
können, um vielfältigste (disziplinäre) Forschungsfragen zu beantworten. Im Rahmen der Sektion möchten
wir unterschiedliche digitale Verfahren und Methoden des Annotierens vorstellen und zugleich aufzeigen,
dass diese nicht nur in unterschiedlichen fachwissenschaftlichen Forschungskontexten verwendet
werden, sondern zugleich auch mediale Grenzen des “Textuell-Bildlichen” überwinden können.
Insbesondere soll der Frage nachgegangen werden, auf welche Weise Annotationen von Bildern,
Digitalisaten und Fotografien - z.B. Zeichen, Muster, Areas etc. - erstellt und wie diese technologisch so
aufbereitet werden können, dass sie such- und recherchierbar, nach internationalen Daten- und
Metadatenstandards gespeichert und nachgenutzt werden können. Im Mittelpunkt steht die Frage, wie
sich aus Bildern maschinenlesbare Informationen gewinnen lassen und diese zugleich weiter verarbeitet
werden können. Hierbei wird grundsätzlich von der These ausgegangen, dass - unabhängig von der je
spezifischen fachwissenschaftlichen Fragestellung - bestimmte Methoden, Verfahren und Technologien
des digitalen Annotierens auf unterschiedlichstes Datenmaterial angewandt werden können.
Nach einem einleitenden Vortrag, der diesen Spannungsbogen thematisiert, wird in drei 20minütigen
Vorträgen der Einsatz von digitalen Annotationstools in unterschiedlichsten Fachdisziplinen und im
Kontext besonders Bilddaten-intensiver Forschungsvorhaben beleuchtet:

1. Einleitung (Harald Lordick, Stefan Schmunk, Sibylle Söring)
2. Tools und Standards für die Bilderflut: Image Services und Annotationen mit IIIF,
OpenAnnotation, Mirador, digilib und TextGrid (Robert Casties, Ubbo Veentjer)
3. Anwendungsbeispiel / Projektwerkstatt: Text – Bild – Inschrift. Hieroglyphenschrift und Sprachen
der Maya annotieren (Christian Prager, Frauke Sachse)
4. Kodikologie meets Topologie - topologisches Retrieval als innovative, nicht-textuelle Form der
Bedeutungsextraktion aus automatisch gewonnenen oder manuell erstellten Bildannotationen
(Jochen Graf)
Aus unterschiedlicher, sowohl technischer als auch semantisch-methodischer Perspektive, gehen die
einzelnen Beiträge dabei der Frage nach dem Wandel, aber auch nach den Möglichkeiten der Annotation
als geisteswissenschaftlichem Verfahren im digitalen Medium nach. Welche (auch fächerübergreifenden)
Methoden und Verfahren werden mit den entsprechenden Tools unterstützt bzw. erleichtert? Welche
Anwendungsszenarien werden bereits praktiziert, wo sind derzeit noch Desiderate zu formulieren? Wie
können diese - auch disziplinen-unabhängig - umgesetzt werden? Und nicht zuletzt: Wie funktioniert der
Brückenschlag zwischen Text und Bild, zwischen Information und Interpretation? Dabei werden
verschiedene Lösungsansätze von TextGrid und DARIAH-DE aufgezeigt, um die disziplinübergreifenden
Synergien herauszuarbeiten, die eine digitale Forschungsinfrastruktur ermöglicht.

DHd2015 Graz ∙ Sektion „Das Wissen der Bilder. Spielarten des digitalen Annotierens“ ∙ Abstracts Vorträge

______________________________________________________________________

Inhalt
1.

Tools und Standards für die Bilderflut: Image Services und Annotationen mit IIIF,
OpenAnnotation, Mirador, digilib und TextGrid (Casties, R.; Veentjer, U.)

2.

Projektwerkstatt / Anwendungsbeispiel: Text – Bild – Inschrift. Hieroglyphenschrift und
Sprachen der Maya annotieren
2.1 Digitale Epigraphik – Die Erforschung der Hieroglyphentexte und Bildbotschaften der
Maya in der Virtuellen Forschungsumgebung TextGrid (Prager, C.)
2.2 Digitale Erschließung und systematische Annotation kolonialer Lexikographien am
Beispiel der Mayasprache K‘ich’e (Sachse, F. et al.)

3.

Kodikologie meets Topologie – Topologisches Retrieval als innovative, nicht-textuelle
Form der Bedeutungsextraktion aus automatisch gewonnenen oder manuell erstellten
Bildannotationen in DARIAH-DE (Graf, J.)

DHd2015 Graz ∙ Sektion „Das Wissen der Bilder. Spielarten des digitalen Annotierens“ ∙ Abstracts Vorträge

______________________________________________________________________

1.
Tools und Standards für die Bilderflut: Image Services und
Annotationen mit IIIF, OpenAnnotation, Mirador, digilib und TextGrid
Robert Casties, Max Planck-Institut für Wissenschaftsgeschichte, Berlin
Ubbo Veentjer, SUB Göttingen

Digitale Bilddaten fallen im Forschungsprozess nahezu aller geisteswissenschaftlicher Disziplinen an
– auch solcher, die primär textbasierte Quellen zum Gegenstand haben. Das Spektrum reicht dabei
von Buch- und Manuskriptdigitalisaten über digitalisierte Gemälde und Zeichnungen oder
Abbildungen von Sammlungsobjekten bis hin zu Fotografien z.B. historischer Inschriften. Im Vortrag
sollen technische Standards und Lösungen für Image Services und Annotationen präsentiert
werden, die neue Arbeitsweisen mit Bildern im Netz ermöglichen, indem sie erlauben, Bilder
unabhängig von ihrem Speicherort zu betrachten, detailliert zu referenzieren, zu annotieren und
eigene Präsentationen und Editionen vorhandener Bilder zu erzeugen und zu publizieren.
Am Beispiel der Virtuellen Forschungsumgebung TextGrid1 und dem hier angebotenen ImageDienst digilib2 soll gezeigt werden, wie Bildservices die Weiter- und Nachnutzbarkeit von Bilddaten
erhöhen, und wie durch die Integration interoperabler Standards für Bild- und Annotationsserver
bessere Werkzeuge bereitgestellt werden können. In diesem Zusammenhang werden auch die
aktuellen Standards des International Image Interoperability Framework (IIIF)3 für Bild- und
Metadaten-Server und die verwandten Standards OpenAnnotation4 und SharedCanvas5 vorgestellt.
Bilder, die in digitalen Archiven abgelegt werden, sind oft nicht für die Darstellung im Internet
geeignet. Wunschformate für die Archivierung von Bilddateien sind - im Kontext der DFGPraxisregeln „Digitalisierung“6 - TIFF oder JPEG-2000, welche von Webbrowsern jedoch nicht
dargestellt werden. Des weiteren werden möglichst hoch aufgelöste Bilder für die Archivierung
angestrebt, während an mobile Geräte Bilder mit geringerer Auflösung ausgeliefert werden sollen.
An dieser Stelle kommt ein Image-Service ins Spiel, der – wie das in TextGrid integrierte Werkzeug
digilib - die originalen, hochaufgelösten Bilddaten in angepassten Auflösungen und web-tauglichen
Bildformaten ausliefern kann.
Um Programme zur Darstellung digitaler Objekte nicht für jeden eingesetzten Image-Service
anpassen zu müssen, kann der interoperable Standard IIIF-Image-API genutzt werden, der festlegt,
wie von einem IIIF-konformen Image-Service Bilder in verschiedenen Größen oder Formaten
abgerufen werden können. Der IIIF-Standard beschreibt zudem, in welchem Metadatenformat
Kollektionen von Bildern beschrieben werden; außerdem wird ein Format für Bildannotation
spezifiziert. Somit können IIIF-konforme Programme - wie etwa der Mirador Viewer7 Bildsammlungen verschiedener Institutionen, die Daten im IIIF-Format bereitstellen, darstellen, z.B.
aber auch Bilder und Metadaten verschiedener Institutionen im selben Workspace anzeigen und
eine Annotation dieser Bilder ermöglichen.
DHd2015 Graz ∙ Sektion „Das Wissen der Bilder. Spielarten des digitalen Annotierens“ ∙ Abstracts Vorträge
1

http://textgrid.de
http://digilib.sf.net
3
http://iiif.io
4
http://www.openannotation.org/
5
http://iiif.io/model/shared-canvas/
6
http://www.dfg.de/formulare/12_151/12_151_de.pdf
7
https://github.com/DMSTech/mirador
2

______________________________________________________________________
Durch die jeweils spezifische Trennung und Standardisierung der Formate und Schnittstellen für
Bilder und Metadaten ist es heute für Forscher aller Disziplinen möglich, eigene Bildkollektionen,
Editionen und Präsentationen zu erstellen und zu publizieren, aber auch, die Bilder aus
unterschiedlichen Repositorien aus aller Welt im Rahmen neuer Forschungskontexte neu zu
kombinieren und zu präsentieren.
Im Vortrag soll der Stand der Integration von IIIF bei TextGrid und digilib vorgestellt und ein
Ausblick auf die zukünftige Integration von Annotationsmöglichkeiten gegeben werden.

DHd2015 Graz ∙ Sektion „Das Wissen der Bilder. Spielarten des digitalen Annotierens“ ∙ Abstracts Vorträge

______________________________________________________________________

2. Projektwerkstatt / Anwendungsbeispiel:
Text – Bild – Inschrift. Hieroglyphenschrift und Sprachen der Maya
annotieren

2.1
Digitale Epigraphik - Die Erforschung der Hieroglyphentexte und Bildbotschaften der
Maya in der Virtuellen Forschungsumgebung TextGrid
Dr. Christian Prager, Rheinische Friedrich-Wilhelms-Universität Bonn
Die nur teilweise entzifferte Hieroglyphenschrift und Sprache der Mayakultur steht im Mittelpunkt
eines Forschungsprojekts der NRW Akademie der Wissenschaften, das in Kooperation zwischen
den Universitäten Bonn und Göttingen durchgeführt wird. Ziel ist die Erstellung einer
Textdatenbank und ein darauf basierendes Wörterbuch des Klassischen Maya, das zwischen 250 bis
950 n.Chr. auf rund zehntausend Text- und Bildträger überliefert ist. Sie ermöglichen einzigartige
Perspektiven auf Sprache, Kultur und Geschichte der vorspanischen Maya. Bis heute fehlen
allerdings eine systematische Dokumentation sowie die umfassende Analyse dieser Quellen. Diese
erlaubten eine präzise Untersuchung des Maya, indem Textpassagen verglichen werden, Bildinhalte
mit Textpassagen korreliert oder die Beschaffenheit oder Funktion eines Textträger in der Inschrift
erfasst und damit rätselhafte Textpassagen verständlich werden. Bislang war ein derartig
systematisches und vernetztes Arbeiten mit Text, Bild und Informationsträgern nicht möglich, da
die notwendige Technologie noch nicht existierte. Im Rahmen des Projekts werden die Quellen
systematisch und nach einheitlichen Standards beschrieben, das Ausgangsmaterial auf der Basis
von XML maschinenlesbar gemacht und auf diese Weise die Grundlagen für die Kompilation des
Wörterbuchs geschaffen. Zu diesem Zweck werden in der VRE TextGrid Tools und Workflows
entwickelt, welche I. die Dokumentation der Schrift- und Bildträger mit Aufarbeitung des
Forschungsstandes, II. die epigraphisch-linguistische Auswertung der Hieroglyphentexte sowie III.
die Edition der Texte mit Transliteration, Transkription und Übersetzung in einem einzigen System
ermöglichen. Der Textträger erhält dadurch eine ‚Biographie‘, die eng mit dem Textinhalten
verwoben ist und bei der Bedeutungsanalyse von Wörtern berücksichtigt wird.
2.2
Digitale Erschließung und systematische Annotation kolonialer Lexikographien am
Beispiel der Mayasprache K'iche'
jun. Prof. Dr. Frauke Sachse (Rheinische Friedrich-Wilhelms-Universität Bonn)
Prof. Dr. Michael Dürr (Zentral- und Landesbibliothek Berlin / Freie Universität Berlin)
Christian Klingler M.A. (Rheinische Friedrich-Wilhelms-Universität Bonn)

Gegenstand des hier vorgestellten Forschungsvorhabens ist die Entwicklung eines Tools zur
korpusorientierten Erfassung kolonialzeitlicher Wörterbücher amerindischer Sprachen. An der
Abteilung für Altamerikanistik der Universität Bonn wurde mit dem Tool for Systematic
Annotation of Colonial K'iche' (TSACK) der Prototyp einer Software-Anwendung entwickelt, mit
dem sich koloniale Lexikographien der Mayasprache K’iche’ in ein maschinenlesbares Korpus
im XML-Standard überführen lassen. Kernproblem der Erfassung sind die nicht
standardisierten Orthographien der Wörterbücher, die vereinheitlicht werden müssen, um
Lexeme einzeln suchbar zu machen und multiple semantische Korrelationen aufzuzeigen.

Dieser Transkriptionsprozess setzt die semantische Zuordnung und morphologische Analyse
der kolonialen Lexikon-Einträge voraus. Da Mayasprachen agglutinierend sind, müssen
Wortformen bis auf die Wurzel heruntergebrochen werden, um einzelne Lemmata zu
isolieren. TSACK unterstützt den Prozess von Transkription, Lemmatisierung und Glossierung
im Rahmen eines halbautomatisierten Auszeichnungsverfahrens. Das Tool vereinfacht den
Arbeitsprozess, minimiert die Fehlerquote und beschleunigt im Vergleich zu herkömmlichen
XML-Editoren die Auszeichnung größerer Datenmengen. Das hier vorgestellte
Forschungsvorhaben will einheitliche Erfassungskriterien für koloniale Lexikographien
definieren und das Tool in der TextGrid-Umgebung so weiterentwickeln, dass es für die
Auszeichnung vergleichbarer Wörterbücher zu anderen Sprachen nutzbar wird.

DHd2015 Graz ∙ Sektion „Das Wissen der Bilder. Spielarten des digitalen Annotierens“ ∙ Abstracts Vorträge

______________________________________________________________________

3. Kodikologie meets Topologie — Topologisches Retrieval als
innovative, nicht-textuelle Form der Bedeutungsextraktion aus
automatisch gewonnenen oder manuell erstellten Bildannotationen in
DARIAH-DE
Jochen Graf, Universität Köln, Historisch-Kulturwissenschaftliche Informationsverarbeitung

In den letzten Jahren sind in der (Kunst-)Geschichte zahlreiche Systeme zur Bildannotation
entstanden. Das Projekt Meta-Image [War11], zum Beispiel, betrachtet Bildannotation im Web als
ein Problem von Bildern und Hyperlinks. Während es für textbasierte wissenschaftliche Arbeit
Standardtechniken gibt, mit denen Bezüge zwischen Textstellen hergestellt werden können
(Fußnoten, Hyperlinks), fehlt ein adäquater Mechanismus für die kollaborative Arbeit mit Bildern
[Hel07]. Die Plattform Sachsenspiegel_online8 [1] integriert einen graphischen Editor, der es
erlaubt, Bilddetails mit Rechtecken zu markieren, die wiederum auf die textuelle Information eines
Normvokabulars verweisen. Bei diesen und ähnlichen Systemen zur Bildannotation ist eine enge
Orientierung am Medium Text zu erkennen: Bilder werden vorzugsweise durch Text erklärt und die
Methoden der Bildannotation orientieren sich an denen der Textedition.
Hingegen gehört eine nicht-textuelle, am Medium Bild orientierte Herangehensweise aus Sicht der
(kunst-)geschichtlichen Hermeneutik zu den neueren methodischen Entwicklungen der
Bildinterpretation [Bohn08]. Der ursprünglich aus der Mathematik stammende und von den
Medien- und Kulturwissenschaften übernommene Begriff der Topologie, zum Beispiel, vermeidet
einen text-orientierten Zugang zum Bild. Ein kürzlich erschienener Tagungsband behandelt
Topologie im Hinblick auf barocke Rechts-Links-Symbolik bis hin zu poetologischer Topologie
[Guen07]. Topologie begegnet uns auch in den Methoden vieler geisteswissenschaftlicher
Disziplinen. Die Kodikologie, beispielsweise, beschäftigt sich mit der räumlichen Disposition von
Büchern. Sie kann aus dem strukturellen Aufbau von Buchseiten—aus der Symmetrie oder
Asymmetrie der Textspalten, aus der Breite der Seitenränder oder aus der Größe und dem Format
von Buchmalereien—auf den Buchtyp oder die Herkunft von Handschriften schließen [Bar14].
Stellt man die thematische und methodische Vielfalt des Raum-Topologie-Aspekts in den
Geisteswissenschaften den aktuellen softwaretechnischen Bestrebungen im Bereich des Semantic
Web entgegen, fällt auf, dass uns topologische oder eigentlich topographische
Informationssysteme bisher lediglich in Form von Geographischen Informationssystemen zur
Verfügung stehen. Mit Geographischen Informationssystemen können wir den raum-zeitlichen
Kontext von Artefakten analysieren und visualisieren—die Systeme erschließen uns jedoch nicht
die innere räumliche Struktur der Artefakte selbst.
eCodicology9 ist ein Bildanalysetool, welches mithilfe von Algorithmen aus der Mustererkennung
semantisch zusammengehörige Teilflächen digitalisierter, mittelalterlicher Handschriftenseiten
erkennen und annotieren, und dadurch Annahmen über die kodikologischen Gestaltungsmerkmale
der Seiten treffen kann. Semantic Topological Notes (SemToNotes)10 ist ein manuelles
8

http://www.sachsenspiegel-online.de/
http://www.ecodicology.org/
10
http://hkikoeln.github.io/SemToNotes/
9

Bildannotationstool, welches neben einem Shared Canvas11 RDF Editor auch ein topologisches
Retrievalsystem integriert. Beide Werkzeuge werden derzeit im Rahmen von DARIAH-DE
entwickelt. Die Projekte verfolgen gemeinsam ein “nicht-textuelles Ziel”. Sie untersuchen, wie viel
Semantik eigentlich schon in den graphischen Annotationen selbst und deren Koordinaten steckt,
noch vor einer textuellen Erschließung und Beschreibung der Digitalisate.
Besonders prägnant wird die Frage, wenn es sich um illuminierte mittelalterliche Handschriften
handelt, in denen Figuren mit ganz bestimmten Gesten und Gebärden abgebildet sind. Hier spielen
Abstände, Richtungen und Winkel, welche die Figuren und ihre Körperteile zueinander einnehmen,
eine entscheidende Rolle. Die Analyse von Gesten in mittelalterlichen Handschriften ist schon in
einer Monographie von Karl von Amira aus dem Jahre 1905 als ein topologisches Problem
aufgefasst worden [Amir05]. Mit einem topologischen Retrievalsystem wird eine ikonographische
Analyse der Bilderhandschriften nicht nur über textuelle Information ermöglicht, sondern zusätzlich
auf Basis von polygonalen graphischen Koordinatendaten.
Literatur:
[Bar14] Vladimir Baranov, Kateřina Horníčková, Elena Lemeneva, Dóra Sallay, Gerhard Jaritz.
Medieval Manuscript Manual. URL=http://web.ceu.hu/medstud/manual/MMM/ [2014-10-30]
[Schm14] Ruth Schmidt-Wiegand. Gebärden. In: Handwörterbuch zur deutschen Rechtsgeschichte
(HRG), URL=http://www.HRGdigital.de/HRG.gebaerden [2014-08-01]
[Pan11] Pandel, Hans-Jürgen. 2011. Bildinterpretation. Die Bildquelle im Geschichtsunterricht.
Wochenschau Verlag, Schwalbach, 2011
[Schl11] Joseph Schlecht, Bernd Carqué, Björn Ommer. 2011. Detecting Gestures in Medieval
Images. In: IEEE International Conference on Image Processing (ICIP 2011)
[War11] Martin Warnke. 2011. Motive vernetzen: Meta-Image als Bild-Zettelkasten. Bilddiskurse in
Zeiten
des
Internets.
URL=http://www2.leuphana.de/metaimage/Material/Texte/KUNSTMAGAZIN_11121201_web.pdf
[Bohn08] Ralf Bohnsack. 2009. The Interpretation of Pictures and the Documentary Method. In:
Historical Social Research, Vol. 34, No. 2 (128), 2009
[Guen07] Stephan Günzel (Hrsg.). 2007. Topologie. Zur Raumbeschreibung in den Kultur- und
Medienwissenschaften, transcript Verlag, Bielefeld, 2007
[Hel07] Sabine Helmers, Heinz-Günter Kuper. 2007. HyperImage – Bildorientierte E-Science
Netzwerke. URL=http://www.uni-lueneburg.de/hyperimage/hyperimage/downloads/helmers.pdf
[Mras06] Marcus Franz Wilhelm Mrass. 2006. Gesten und Gebärden - Begriffsbestimmung und verwendung in Hinblick auf kunsthistorische Untersuchungen. Verlag Schnell & Steiner, Regensburg
2005
[Schm97] Mathias Schmoeckel. 1997. Karl von Amira und die Anfänge der Rechtsärchäologie. Die
rechtsarchäologische Sammlung Karl von Amiras am Leopold-Wenger-Institut. In: Zeitschrift für
Rechtsäarchäologie
und
Rechtliche
Volkskunde
17
(1997),
S.
67-81.
URL=http://bsbdipriorkat.bsb.lrz.de/amira/projekt/amira-schmoeckel.pdf

11

http://iiif.io/model/shared-canvas/1.0/index.html

[Wohl91] Reiner Wohlfeil. 1991. Methodische Reflexionen zur Historischen Bildkunde. In:
Historische Bildkunde. Probleme - Wege - Beispiele, hrsg. von Brigitte Tolkemitt und Reiner
Wohlfeil. Zeitschrift für historische Forschung, Berlin, Duncker und Humblot, 1991
[Amir05] Karl von Amira. 1905. Die Handgebärden in den Bilderhandschriften des Sachsenspiegels.
URL=http://digi.ub.uni-heidelberg.de/diglit/amira1905

