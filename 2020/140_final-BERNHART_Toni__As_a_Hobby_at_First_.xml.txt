





Plädoyer für eine Fachgeschichte digitaler Geisteswissenschaften


Die Geschichte digitaler Geisteswissenschaften wurde bislang kaum erforscht. Schlaglichtartige Beiträge liegen vor (Hoover 2007, Kelih 2008, Cortelazzo/Tuzzi 2008, Viehhauser 2015, Weitin 2015, Jannidis 2015, Twellmann 2016, Thaller 2017, Schöch 2017, Lauer und Pacyna 2017, Bernhart 2018), doch umfassende Studien, die nicht nur die letzten Jahrzehnte, sondern auch die zahlreichen Vorläufe seit dem späten 18. Jahrhundert in systematischer und historischer Perspektive in den Blick nehmen, gibt es noch nicht.




Der Vortrag möchte für historisches Bewusstsein digitaler Geisteswissenschaften sensibilisieren und für eine Fundierung der Wissenschaftsgeschichte des Faches werben. Denn historisch informierte digitale Geisteswissenschaften sind in der Lage, auf Erfahrungen und Experimente aus mindestens zwei Jahrhunderten zurückzugreifen und diese für die Erkenntnisgewinnung zu nutzen und kritisch zu reflektieren. In ihrer genuinen Koppelung von Informatik, die tendenziell eher gegenwartsbezogen operiert, und geisteswissenschaftlichen Disziplinen, die tendenziell größere Aufmerksamkeit auf die Betrachtung historischer Wissensbestände legen, sind die digitalen Geisteswissenschaften dazu berufen, historische Perspektivierungen bei ihrer Arbeit an Modellierung und Interpretation kultureller Artefakte zu integrieren und zu systematisieren. Historische Perspektivierung macht die gesellschaftliche Relevanz digitaler Geisteswissenschaften transparent und dient der didaktischen Vermittlung des Faches, indem Zeitverlauf und Erkenntnisgewinn in Korrelation miteinander erzählt werden können. Unter den zahlreichen Strängen einer Wissenschaftsgeschichte digitaler Geisteswissenschaften greift der Vortrag den Aspekt künstlerischer Produktion als Modellierung heraus und demonstriert diese am Beispiel der Arbeiten von Theo Lutz und Wilhelm Fucks.






Künstlerische Produktion als Modellierung


Das Thema der Jahrestagung stellt Modellierung und Interpretation als zentrale Arbeitsfelder der Digital Humanities in den Vordergrund. Modellierung wird dabei jedoch vorwiegend theoretisch als Mittel der Erkenntnisgewinnung verstanden. Ein anderer Aspekt der Modellierung ist die künstlerische Produktion, die aber nicht zu den originären Arbeitsgebieten der Digital Humanities zählt. Während im internationalen Feld der Digital Studies die Grenze zwischen den Künsten und den Wissenschaften sehr viel stärker aufgehoben scheint und auch akademische Forschung sich an künstlerischer Produktion beteiligt, verharren die Digital Humanities, insbesondere jene des deutschsprachigen Raums, in eher beobachtendem Status. Sie sehen Analyse und Interpretation als ihre primären Zuständigkeitsbereiche und halten weiterhin die Dichotomie zwischen Medienkunst und Medienwissenschaft aufrecht. Digitale Kunst wird außerhalb der Digital Humanities produziert; für künstlerische Produktion werden Digital Humanities kaum genutzt. Dabei verweist gerade die Metapher der Spielräume auf den transgressiven Charakter experimenteller Laboratorien, die in den Digital Humanities bereitstehen.


Die Frühzeit digitaler Geisteswissenschaften und insbesondere die Kybernetik der späten 1950er und 1960er Jahre waren in dieser Hinsicht sehr viel verspielter und experimenteller. Vertreter akademischer Disziplinen wie etwa der Mathematik und Physik verstanden Modellierung ganz selbstverständlich auch im Sinne künstlerischer Produktion. Beispiele dafür sind der Mathematiker Theo Lutz und der Physiker Wilhelm Fucks. Wissenschaftsgeschichtlich bezeichnend ist ferner, dass sich in dieser Zeit aus Mathematik und Elektrotechnik ein neues Fach zu emanzipieren beginnt, das in den 1970er Jahren unter dem Namen Informatik sehr rasch an internationaler Bedeutung gewinnt. Dabei war in dieser frühen Zeit noch nicht ausverhandelt, für welche technischen, angewandten, theoretischen und geisteswissenschaftlichen Problemlösungen die Informationsverarbeitung zuständig sein soll; vielmehr waren Explorationen in sehr unterschiedliche Richtungen charakteristisch (Gunzenhäuser 1968).






„Stochastische Texte“ von Theo Lutz


Theo Lutz (1932–2010), Mathematikstudent an der vormaligen Technischen Hochschule, heute Universität Stuttgart, schrieb im Frühjahr 1959 an der hochschuleigenen Zuse Z 22 seine Diplomarbeit über elektrotechnische Netzwerke. In seiner Freizeit entwickelte er die Idee zu einem Umkehrschub: Wenn es mithilfe computergestützter und statistischer Verfahren möglich ist, Texte zu analysieren und zu interpretieren, muss es auch möglich sein, mithilfe derselben Verfahren Texte zu produzieren. Sein Lehrer Max Bense, Philosoph der rationalen Avantgarde, und sein Studienfreund Rul Gunzenhäuser, der später gemeinsam mit Helmut Kreuzer das Grundlagenwerk „Mathematik und Dichtung“ herausgeben (Kreuzer/Gunzenhäuser 1965) und die „Zeitschrift für Literaturwissenschaft und Linguistik (LiLi)“ begründen und in Stuttgart zu einem Pionier der Informatik avancieren wird, waren begeistert von Lutz’ Idee und unterstützten das Vorhaben. Das Ergebnis waren die „Stochastischen Texte“, die Wortmaterial aus Franz Kafkas Roman „Das Schloss“ (1926) wahrscheinlichkeitsmathematisch zu grammatikalisch sinnvollen Sätzen kombinierten (Lutz 1959).
 Programmiert wurde die Z 22 im sogenannten Freiburger Code. Eine besondere Herausforderung stellte dabei die maschinelle Generierung der für die Textherstellung erforderlichen Zufallszahlen dar. Mit seinen „Stochastischen Texten“ schrieb Lutz Literaturgeschichte: Sie waren nach den „Love Letters“ von Christopher Strachey die ersten mithilfe einer programmierten Rechenmaschine generierten Texte in deutscher Sprache (Strachey 1954). Doch der ursprüngliche Zweck der „Stochastischen Texte“ war ein anderer: Sie sollten als Vergleichstexte zur Untersuchung natürlichsprachlicher Texte dienen (Bernhart 2019: 329–331, Bernhart/Richter 2019, Reiter/Bernhart eingereicht). Die Rekonstruktion der Genese der „Stochastischen Texte“ wird im Vortrag flankiert von der Berücksichtigung der poetologischen, philosophischen, politischen und ästhetischen Voraussetzungen, die für maschinelle und programmgesteuerte Generierung von Kunst in den späten 1950er und 1960er Jahren stil- und programmbildend waren.








Wilhelm Fucks und Neue Musik


Wilhelm Fucks (1902–1990) war Physiker an der RWTH Aachen. In den Geisteswissenschaften ist Fucks vor allem für seine sehr zahlreichen kybernetischen Forschungen zu Literatur, Musik und bildender Kunst und für die beiden Monographien „Formeln zur Macht“ (Fucks 1965) und „Nach allen Regeln der Kunst“ (Fucks 1968) bekannt. Bislang kaum beachtet wurden dagegen seine kompositorischen Versuche.


Erstaunlich ist dabei der Echoraum, den sich Fucks für seine Kompositionen verschaffen konnte. Dank seines kommunikativen Talents und seiner wissenschaftlichen Adaptionsfähigkeit war er in der Lage, sich innerhalb weniger Jahre als zeitgenössischer Komponist zu etablieren und sich Ende der 1960er Jahre neben internationalen Vertretern der Neuen Musik wie Iannis Xenakis und John Cage zu behaupten, obwohl er auf dem Gebiet des musikalischen Schaffens Amateur war. Seine ersten Versuche reichen in die Zeit der letzten Monate des Zweiten Weltkriegs zurück, wie er im Diskussionsprotokoll des Bandes zum Symposium „Information Theory“ an der Royal Institution 1955 in London festhält. Zunächst habe er sich hobbymaßig, „as a hobby at first“ (Fucks 1956: 169), mathematisch mit Fragen literarischer Stilistik beschäftigt. Erst später habe er sich mit den Theorien und Ansätzen etwa von Benoit Mandelbrot, Gustav Herdan, Claude E. Shannon oder Norbert Wiener vertraut gemacht und seine Studien auf den Bereich der Musik ausgedehnt (ebd.).


Unter dem Eindruck der probabilistischen Logik von John von Neumann (Neumann 1956) intensivierte Fucks seine Beschäftigung mit stochastischer Musik, suchte in Paris den Austausch mit Abraham Moles und den Kontakt zu Iannis Xenakis, die ihn in den Kreis um den einflussreichen Experimentator und Theoretiker der Neuen Musik Hermann Scherchen einführten. Auf Scherchens legendärer Tagung in Gravesano im Schweizer Tessin stellte Fucks schließlich 1962 seine umfangreichen harmonischen Entropieforschungen sowie eigene Kompositionen vor, die – ähnlich wie Lutz’ Generierung der „Stochastischen Texte“ – aus der „umgekehrten“ Anwendung empirischer Verteilungen hervorgingen (Fucks 1962). Für den Vortrag seiner Stücke konnte Fucks die namhafte Pianistin Margot Pinter (1915–1982) gewinnen, Professorin für Klavier am Innsbrucker Konservatorium und Spezialistin für Neue Musik. Eine bislang unbekannte Tonbandaufzeichnung davon konnte ich kürzlich im Archiv der Akademie der Künste, Berlin, ausfindig machen (Akademie der Künste, Archiv, Signatur AVM-31 6332, Band 14 und Band 15). Die aufgezeichnete Musik und vor allem die ebenfalls aufgezeichnete Plenumsdiskussion im Anschluss an den Vortrag sind aufschlussreiche, bislang unbekannte Quellen, die im Vortrag vorgestellt werden.




Fucks’ weitere Stationen führten nach Berlin und London. Auf Einladung des Architekten und Präsidenten der Berliner Akademie der Künste Hans Scharoun stellte Fucks 1965 auf einer prominent besetzten Tagung zum Thema „Kybernetik“ in Berlin seine Musiken vor. In London war Fucks als Komponist auf der von Jasia Reichardt kuratierten Ausstellung „Cybernetic Serendipity“ 1968 vertreten (Reichardt 1968), die als eine der ersten internationalen Ausstellungen kybernetischer Künste gilt. Auf der gleichnamigen Langspielplatte, die im Rahmen der Ausstellung erschien, ist Fucks’ Stück „Quatro due [sic]“, gespielt von Margot Pinter, zu hören. Auf der Platte vertreten sind unter anderem John Cage, Iannis Xenakis und James K. Randall (Cybernetic Serendipity Music 1968).






Spielräume künstlerischer Produktion in Kybernetik und digitalen Geisteswissenschaften


Im Fazit des Vortrags wird danach gefragt, inwiefern sich Kybernetik und Digital Humanities hinsichtlich künstlerischer Produktion unterscheiden. Produktiv dafür kann die schwierige Vergleichbarkeit der beiden Bewegungen sein: Die Kybernetik operierte vorwiegend quantitativ und statistisch und delegierte die Interpretation an eine imaginäre Zukunft; die Digital Humanities dagegen integrierten quantitative und qualitative Verfahren von Anfang an und gleichermaßen in die Modellierung und Interpretation der Untersuchungsgegenstände. Die Dichotomie zwischen Medienkunst und Medienwissenschaft bleibt dabei tendenziell aufrecht, während die Kybernetik ihre Spielräume sehr viel transgressiver auch für künstlerische Produktionen nutzte. Spielerischer scheinen derzeit digitale Medienkünste zu agieren, die in und neben ihrer künstlerischen Produktion oft auch forschend tätig sind. Auch die zahlreichen KI-Labore (etwa von Google oder OpenAI) pflegen neben ihrer angewandten Forschung mitunter spielerischen Umgang mit Künstlicher Intelligenz, der bisweilen an die Experimente von Lutz und Fucks erinnert. Der Geist der Kybernetik entsprang der jungen und technikbegeisterten Aufbruchstimmung der Nachkriegszeit, während digitale Geisteswissenschaften und Künste mittlerweile auf kollaborative Projekterfahrungen, Tools und Formate eines halben Jahrhunderts digitaler Kompetenz zurückblicken und auch kritischere und differenziertere Positionen vertreten als die historische Kybernetik. Hinsichtlich der Einmischung in künstlerische Produktion liegen in den Digital Humanities Spielräume verborgen, über deren (Nicht-)Nutzung nachzudenken lohnen kann.







  

    

Der Beitrag entstand im Rahmen des Forschungsprojekts „Quantitative Literaturwissenschaft“, gefördert durch die Deutsche Forschungsgemeinschaft (DFG) – Projektnummer 259167649.




Für die Genehmigung der Verwendung von bislang unveröffentlichtem Text- und Bildmaterial von Theo Lutz danke ich Hannelore und Heike Lutz sowie dem Deutschen Literaturarchiv (DLA) Marbach.




Anhand des Nachlasses von Theo Lutz, der seit 2019 im Deutschen Literaturarchiv (DLA) Marbach liegt, lässt sich die komplexe und voraussetzungsreiche Genese der „Stochastischen Texte“ sehr genau und detailreich rekonstruieren. Vertiefende Ausführungen dazu bieten der Beitrag von Reiter/Bernhart (eingereicht) und zwei Vorträge von Toni Bernhart: „Beiwerk als Werk. ‚Stochastische Texte‘ von Theo Lutz“ bei der 18. internationalen Tagung der Arbeitsgemeinschaft für germanistische Edition „Werk und Beiwerk. Zur Edition von Paratexten“ vom 12. bis 15. Februar 2020 im Deutschen Literaturarchiv (DLA) Marbach und „Theo Lutz auf Zuse Z 22: ‚Stochastische Texte‘ (1959). Präliminarien einer Edition“ beim XIV. Kongress der Internationalen Vereinigung für Germanistik „Wege der Germanistik in transkulturellen Perspektiven“ vom 26. Juli bis 2. August 2020 in Palermo.




Für die Genehmigung der Verwendung von bislang unveröffentlichtem Text-, Bild- und Tonmaterial von Wilhelm Fucks danke ich Thomas Fucks, Anton Voigt und dem Archiv der Akademie der Künste, Berlin.









Bibliographie




Bernhart, Toni
 (2018): „Quantitative Literaturwissenschaft: Ein Fach mit langer Tradition?“ in: Bernhart, Toni / Willand, Marcus / Richter, Sandra / Albrecht, Andrea (Hg.): 
                        
Quantitative Ansätze in den Literatur- und Geisteswissenschaften. Systematische und historische Perspektiven.
 Berlin, Boston: Walter de Gruyter 207–219 
                        
https://doi.org/10.1515/9783110523300-009
 [6.1.2020].
                    




Bernhart, Toni
 (2019): „Rul Gunzenhäuser und die Stuttgarter Schule der mathematischen Literaturwissenschaften“, in: Albrecht, Andrea / Bonitz, Masetto / Skowronski, Alexandra (Hg.): 
                        
Max Bense. Werk – Kontext – Wirkung.
 Stuttgart: Metzler 323–335.
                    




Bernhart, Toni / Richter, Sandra
 (2019): „Maschinen können Gedichte schreiben“, in: Süddeutsche Zeitung, Nr. 244, vom 22. Oktober 2019: 12.
                    




Cortelazzo, Manlio / Tuzzi, Arjuna
 (2008): 
                        
Metodi statistici applicati all'italiano.
 Bologna: Zanichelli.
                    




Cybernetic Serendipity Music
 (1968). ICA [LP]. 
                        
https://cyberneticserendipity.net/
 [6.1.2020].
                    




Fucks, Wilhelm
 (1956): „Mathematical Theory of Word Formation“, in: Cherry, Colin (ed.): 
                        
Information Theory. Papers read at a Symposium on 'Information Theory' held at the Royal Institution, London, September 12th to 16th 1955.
 London: Butterworth 154–170.
                    




Fucks, Wilhelm
 (1962): „Mathematische Musikanalyse und Randomfolgen. Musik und Zufall. Musical Analysis by Mathematics. Random Sequences“, in: 
                        
Gravesaner Blätter
 6/23–24: 132–155. 
                        
https://archiv.adk.de/objekt/2971402
 [6.1.2020].
                    




Fucks, Wilhelm
 (1965): 
                        
Formeln zur Macht. Prognosen über Völker, Wirtschaft, Potentiale.
 Stuttgart: Deutsche Verlagsanstalt.
                    




Fucks, Wilhelm
 (1968): 
                        
Nach allen Regeln der Kunst. Diagnosen über Literatur, Musik, bildende Kunst – die Werke, ihre Autoren und Schöpfer.
 Stuttgart: Deutsche Verlagsanstalt.
                    




Gunzenhäuser, Rul
 (Hg.) (1968): 
                        
Nicht-numerische Informationsverarbeitung. Beiträge zur Behandlung nicht-numerischer Probleme mit Hilfe von Digitalrechenanlagen
. Wien / New York: Springer.
                    




Hoover, David L.
 (2007): „Quantitative Analysis and Literary Studies“, in: Siemens, Ray / Schreibman, Susan (eds.): 
                        
A Companion to Digital Literary Studies
 (= Blackwell companions to literature and culture 50). Malden, MA: Blackwell: 517–533 
                        
http://www.digitalhumanities.org/companion/DLS/
 [6.1.2020].
                    




Jannidis, Fotis
 (2015): „Perspektiven empirisch-quantitativer Methoden in der Literaturwissenschaft. Ein Essay“, in: 
                        
Deutsche Vierteljahrsschrift für Literaturwissenschaft und Geistesgeschichte (DVJs)
 89/4: 657-661.
                    




Kelih, Emmerich
 (2008): 
                        
Geschichte der Anwendung quantitativer Verfahren in der russischen Sprach- und Literaturwissenschaft
 (= Studien zur Slawistik 19). Hamburg: Kovač.
                    




Kreuzer, Helmut / Gunzenhäuser, Rul
 (Hg.) (1965): 
                        
Mathematik und Dichtung. Versuche zur Frage einer exakten Literaturwissenschaft
 (= Sammlung Dialog 3)
                        
.
 München: Nymphenburger Verlagshandlung.
                    




Lauer, Claudia / Pacyna, Jana
 (2017): „Zählen und Erzählen. Mittelalterliche Literatur- und Geschichtswissenschaft im methodischen Dialog“, in: Schweiker, Marcel / Hass, Joachim / Novokhatko, Anna / Halbleib, Roxana (Hg.): 
                        
Messen und Verstehen in der Wissenschaft. Interdisziplinäre Ansätze.
 Wiesbaden: Springer 23–41.
                    




Lutz, Theo
 (1959): „Stochastische Texte“, in: 
                        
augenblick. zeitschrift für tendenz und experiment
 4/1: 3–9.
                    




Neumann, John von
 (1956): „Probabilistic Logics and the Synthesis of Reliable Organisms from Unreliable Components“, in: Shannon, C. E. / McCarthy, J. (eds.): 
                        
Automata Studies
 (= Annals of Mathematics Studies 34). Princeton, NJ: Princeton University Press 43–98.
                    




Reichardt, Jasia
 (Hg.) (1968): 
                        
Cybernetic Serendipity. The Computer and the Arts. A Studio International special issue,
 2nd ed. London: Studio International. 
                        
https://cyberneticserendipity.net/
 [6.1.2020].
                    




Reiter, Nils / Bernhart, Toni
 (eingereicht): „Theo Lutz: Poetry Generation in 1959 on Zuse Z 22“, in: 
                        
Digital Humanities Quarterly. Special Issue on Minimal Computing.






Schöch, Christof
 (2017): „Quantitative Analyse“, in: Jannidis, Fotis / Kohle, Hubertus / Rehbein, Malte (Hg.): 
                        
Digital Humanities. Eine Einführung. Mit Abbildungen und Grafiken.
 Stuttgart: Metzler 279–298.
                    




Strachey, Christopher
 (1954): „The ‘Thinking’ Machine“, in: 
                        
Encounter. A monthly review of literature, the arts, and politics
 13: 25–31. 
                        
http://www.unz.com/print/Encounter-1954oct-00025/
 [6.1.2019].
                    




Thaller, Manfred
 (2017): „Geschichte der Digital Humanities; Digital Humanities als Wissen-schaft“, in: Jannidis, Fotis / Kohle, Hubertus / Rehbein, Malte (Hg.): 
                        
Digital Humanities. Eine Einführung. Mit Abbildungen und Grafiken.
 Stuttgart: Metzler 3–18.
                    




Twellmann, Marcus
 (2016): „Gedankenstatistik. Proto-digitale Wissenschaften vom ‚objektiven Geist‘ und ihre Archivverfahren“, in: Gretz, Daniela / Pethes, Nicolas (Hg.): 
                        
Archiv / Fiktionen. Verfahren des Archivierens in Literatur und Kultur des langen 19. Jahrhunderts.
 Freiburg i. Br. / Berlin / Wien: Rombach 409–431.
                    




Viehhauser, Gabriel
 (2015): „Historische Stilometrie? Methodische Vorschläge für eine Annäherung textanalytischer Zugänge an die mediävistische Textualitätsdebatte“, in: Baum, Constanze / Stäcker, Thomas (Hg.): 
                        
Grenzen und Möglichkeiten der Digital Humanities
 (= Sonderband der Zeitschrift für digitale Geisteswissenschaften 1) 
                        
http://dx.doi.org/10.17175/sb01
 [6.1.2020].
                    




Weitin, Thomas
 (2015): „Digitale Literaturwissenschaft“, in: 
                        
Deutsche Vierteljahrsschrift für Literaturwissenschaft und Geistesgeschichte (DVJs)
 89/4: 651–656.
                    








