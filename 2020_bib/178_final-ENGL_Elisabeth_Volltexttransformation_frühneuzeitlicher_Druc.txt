
  
    
      Im Kontext von OCR bezeichnet 
      Ground Truth manuell korrigierte, fehlerfreie Transkriptionen. Diese werden zum einen für das Training von OCR-Engines, zum anderen für die Evaluation der OCR-Ergebnisse benötigt.
    
    
      Der Gedanke folgt der neunten Empfehlung (“Establish an ‘OCR Service Bureau’”) aus dem Report von Smith und Cordell (2018).
    
    
      Vgl. bspw. die folgenden Projekte, die sich auf unterschiedlich große (Teil-)Bestände beziehen: Helmstedter Drucke Online:
      http://www.hab.de/de/home/wissenschaft/forschungsprofil-und-projekte/helmstedter-drucke-online.html;
      Über 14.000 preußische Drucke des 17. Jahrhunderts online verfügbar:
      https://blog.sbb.berlin/ueber-14-000-preussische-drucke-des-17-jahrhunderts-online-verfuegbar/;
      Projekt Digi20
      https://digi20.digitale-sammlungen.de/de/fs1/about/static.html
    
    
      Nachdem im Jahr 2010 der Aufbau von Infrastrukturen für Forschungsdaten von der DFG ausgeschrieben worden war, wurde drei Jahre später das Förderprogramm „Informationsinfrastrukturen für Forschungsdaten“ eingerichtet. Vgl. DFG 2019: 7.
    
    
      Zur aktuellen Situation des Datenmanagements und der Rolle, die Bibliotheken in diesem Bereich einnehmen (könnten), vgl. Neuroth et al 2019.
    
    
      Die Notwendigkeit einheitlicher Richtlinien wird besonders an Projekten wie “Venice Time Machine” deutlich, dessen bereits vorhandenen 8 TB an Daten aufgrund fehlender einheitlicher Richtlinien und Vorgehensweisen bei der Erfassung der Metadaten für die Forschung vermutlich wertlos sind. Vgl. Castelvecchi 2019: 607.
    
    
      Kempf geht davon aus, dass mit OCR-Software nie völlig fehlerfreie Volltexte generiert werden können. Vgl. Kempf 2015: 274.
    
    
      Während die OCR-Ergebnisse im Rahmen des GoogleBooks-Projekts zunächst insgesamt unbefriedigend, für gebrochene Schriften vollkommen unbrauchbar waren, konnten ab dem Jahr 2008 einzelne Frakturtexte in ausreichender Qualität prozessiert werden. In den letzten Jahren konnte die Erkennungsrate noch deutlich gesteigert werden. Vgl. Wikisource: Google Book Search.
    
    
      Bspw. gibt Google die Fehlerquote im Google Books pauschal mit 1,37 % an (vgl. Kempf 2015: 272). Diese für die wissenschaftliche Nutzung hohe Fehlerrate unterscheidet sich, bedingt durch die Vielfalt an Typen und Layouts sowie den großen Publikationszeitraum der digitalisierten Bücher, von Text zu Text deutlich.
    
    
      https://github.com/tesseract-ocr/tesstrain
    
    
      https://github.com/OCR-D/okralact
    
    
      https://github.com/qurator-spk/dinglehopper
    
  
  
    
      Bibliographie
      
	Baierer, Konstantin / Boenig, Matthias / Hartmann, Volker / Hermann, Elisa / Neudecker, Clemens (2019): 
	„Vom gedruckten Werk zu elektronischem Volltext als Forschungsgrundlage“ (Workshop)
	(, S. 58).
      
      
	Boenig, Matthias / Würzner, Kay-Michael / Binder, Arne / Springmann, Uwe  (2016): 
	„Über den Mehrwert der Vernetzung von OCR-Verfahren zur Erfassung von Texten des 17. Jahrhunderts.“ 
	Vortrag auf der DHd 2016, 7.12.03.2016 in Leipzig ().
      
      
	Boenig, Matthias / Federbusch, Maria / Herrmann, Elisa / Neudecker, Clemens / Würzner, Kay-Michael (2018):
	 „Ground Truth: Grundwahrheit oder Ad-Hoc-Lösung? Wo stehen die Digital Humanities?“.
	Vortrag auf der DHd2018, 28.02.2018 in Köln
	().
      
      
	Castelvecchi, Davide (2019): 
      “Venice ‘Time Machine’ Project Suspended amid Data Row. Disagreements between International Partners Leave Plans to Digitize the Italian City’s History in Limbo” in: 
      Nature 574: 607.
      
      
	DFG  (2019): 
	„Weiterentwicklung des Förderprogramms ‚Informationsinfrastrukturen für Forschungsdaten‘"
	 [6.3.2019 / 26.9.2019].
      
      
	Kempf, Klaus (2015): 
      „Data Curation oder (Retro-)Digitalisierung ist mehr als die Produktion von Daten“ in: 
      o-bib 4: 268–278.
      
      
      Neuroth, Heike / Rothfritz, Laura / Petras, Vivien / Kindling, Maxi  (2019): “Digitales Datenmanagement als neue Aufgabe für wissenschaftliche Bibliotheken” in: Bibliothek. Forschung und Praxis 43: 421–431.
      
	Smith, David A. / Cordell, Ryan  (2018): 
	“A Research Agenda for Historical and Multilingual Optical Character Recognition”
	 [9.12.2019].
      
      
	Wikipedia, Die freie Enzyklopädie  (2019): 
	„Google Books“.
	 [16.6.2019 / 25.9.2019].
      
      
	Wikisource  (2019): 
	“Google Book Search”
	 [22.8.2019 / 26.9.2019].
      
    

