
  
    
      Was tatsächlich bei Amazon passiert ist: 
      https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G
    
    
      Beispiel von https://twitter.com/jessamyn/status/900867154412699649
      bezüglich des www.perspectiveapi.com
      Interfaces, außerdem Davidson et al. (2019)
    
  
  

Bibliographie

Bode, Katherine (Forthcoming 2020): Why You Can’t Model Away Bias, Modern Language Quarterly 81.1. preprint: katherinebode.files.wordpress.com/2019/08/mlq2019_preprintbode_why.pdf [letzter Zugriff 27. September 2019].
                    

Bolukbasi, Tolga / Kai-Wei Chang / James Y Zou / Venkatesh Saligrama /  Adam T Kalai (2016): Man is to computer programmer as woman is to homemaker? debiasing word embeddings. Conference of NIPS.
                    

Buolamwini, Joy / Timnit Gebru (2018): Gender shades: Intersectional accuracy disparities in commercial gender classification. Conference on fairness, accountability and transparency.
                    

Caliskan, Aylin / Joanna J. Bryson  /  Arvind Narayanan. (2017): Semantics derived automatically from language corpora contain human-like biases. Science 356.
                    

Davidson, Thomas / Debasmita Bhattacharya  / Ingmar Weber (2019): Racial Bias in Hate Speech and Abusive Language Detection Datasets. arXiv preprint arXiv:1905.12516. 
                    

Garg, Nikhil /  Londa Schiebinger / Dan Jurafsky  /  James Zou (2018): Word embeddings quantify 100 years of gender and ethnic stereotypes. Proceedings of the National Academy of Sciences.
                    

Gonen, H.  /  Yoav Goldberg (2019): Lipstick on a Pig: Debiasing Methods Cover up Systematic Gender Biases in Word Embeddings But do not Remove Them. Conference of the NAACL.
                    

May, Chandler /  Alex Wang / Shikha Bordia / Samuel R. Bowman  /  Rachel Rudinger (2019): On Measuring Social Biases in Sentence Encoders. Conference of the NAACL.
                    

Mikolov, T. / Chen, K. /  Corrado, G.  /  Dean, J. (2013): Efficient estimation of word representations in vector space. In ICLR.
                    

Sap, Maarten / Dallas Card / Saadia Gabriel / Yejin Choi  /  Noah A. Smith (2019): The Risk of Racial Bias in Hate Speech Detection. Conference of the ACL.
                    

Swinger, Nathaniel / Maria De-Arteaga /  Neil Heffernan IV / Mark Leiserson  /  Adam Kalai (2019): What are the biases in my word embedding?. Conference on Artificial Intelligence, Ethics, and Society (AIES).
                    

Underwood, Ted (2019). Distant Horizons: Digital Evidence and Literary Change. University of Chicago Press.
                    

Zhang, B. H. /  Lemoine, B. / Mitchell, M. (2018): Mitigating unwanted biases with adversarial learning. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society.
                    

Zhao, J. / Wang, T. / Yatskar, M. / Ordonez, V. /  Chang, K. W. (2018): Gender bias in coreference resolution: Evaluation and debiasing methods. arXiv preprint arXiv:1804.06876.
                    


