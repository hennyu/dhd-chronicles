


Bibliographie

   Arnold, T. / Tilton, L.  (2019a): Distant viewing: Analyzing large visual corpora. Digital Scholarship in the Humanities.
  
   Arnold, T. / Tilton, L.  (2019b): Depth in Deep Learning: Knowledgeable, Layered, and Impenetrable.
  
   Bell, P. / Impett, L.  (2019): Ikonographie und Interaktion. Computergestützte Analyse von Posen in Bildern der Heilsgeschichte. Das Mittelalter 24, 31–53.
  
   Deng, J. / Dong, W. / Socher, R. / Li, L. / Li, K. / Fei-Fei, L. (2009): Imagenet: A large-scale hierarchical image database, in: Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference, 248–255.
  
   Doshi-Velez, F. / Kim, B.  (2017): Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608.
  
   Friedler, S.A / Scheidegger, C. / Venkatasubramanian, S. / Choudhary, S., Hamilton, E.P. / Roth, D. (2019): A comparative study of fairness-enhancing interventions in machine learning, in: ACM Conference on Fairness, Accountability, and Transparency (FAT*).
  
   Geirhos, R. / Rubisch, P. / Michaelis, C. / Bethge, M. / Wichmann, F.A. / Brendel, W.  (2019): ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. arXiv preprint arXiv:1811.12231.
  
   Gilpin, L.H. / Bau, D. / Yuan, B.Z. / Bajwa, A. / Specter, M. / Kagal, L.  (2018): Explaining explanations: An overview of interpretability of machine learning, in: 2018 IEEE 5th International Conference on Data Science and Advanced Analytics (DSAA). IEEE: 80–89.
  
   Goodfellow, I. / Pouget-Abadie, J. / Mirza, M. / Xu, B. / Warde-Farley, D. / Ozair, S. / Courville, A. / Bengio, Y.  (2014): Generative adversarial nets, in: Advances in Neural Information Processing Systems: 2672–2680.
  
   Hohman, F.M. / Kahng, M. / Pienta, R. / Chau, D.H.  (2018): Visual Analytics in Deep Learning: An Interrogative Survey for the Next Frontiers. IEEE Transactions on Visualization and Computer Graphics.
  
   Hohman, F. / Park, H. / Robinson, C. / Chau, D.H. (2019): Summit: Scaling Deep Learning Interpretability by Visualizing Activation and Attribution Summarizations. arXiv preprint arXiv:1904.02323.
  
   Ilyas, A. / Santurkar, S. / Tsipras, D. / Engstrom, L. / Tran, B. / Madry, A. (2019): Adversarial examples are not bugs, they are features. arXiv preprint arXiv:1905.02175.
  
   Krizhevsky, A. / Sutskever, I. / Hinton, G.E.  (2012): Imagenet Classification with Deep Convolutional Neural Networks, in: Advances in Neural Information Processing Systems: 1097–1105.
  
   LeCun, Y. / Boser, B. / Denker, J.S. / Henderson, D. / Howard, R.E. / Hubbard, W. / Jackel, L.D. (1989): Backpropagation applied to handwritten zip code recognition. Neural computation 1: 541–551.
  
   Lin, T.-Y. / Maire, M. / Belongie, S. / Hays, J., Perona, P. / Ramanan, D. / Dollár, P. / Zitnick, C.L.  (2014): Microsoft COCO: Common objects in context, in: European Conference on Computer Vision. Springer: 740–755.
  
   Lipton, Z.C. (2016): The mythos of model interpretability, in: 2016 ICML Workshop on Human Interpretability in Machine Learning (WHI 2016), New York, NY.
  
   Mittelstadt, B. / Russel, C. / Wachter, S. (2019): Explaining Explanations in AI, in: ACM Conference on Fairness, Accountability, and Transparency (FAT*).
  
     Olah, C. / Mordvintsev, A. / Schubert, L. (2017): Feature visualization. Distill.
     https://doi.org/10.23915/distill.00007  [letzter Zugriff 26 September 2019] 
  
      Olah, C., Satyanarayan, A., Johnson, I., Carter, S., Schubert, L., Ye, K., Mordvintsev, A. (2018). The building blocks of interpretability. Distill.
                         https://doi.org/10.23915/distill.00010  [letzter Zugriff 26 September 2019] 
  
     Russakovsky, O. / Deng, J. / Su, H. / Krause, J. / Satheesh, S. / Ma, S. / Huang, Z. / Karpathy, A. / Khosla, A. / Bernstein, M. et al. (2015): Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115: 211–252.
    
     Selbst, A.D. / Barocas, S. (2018): The intuitive appeal of explainable machines. Fordham Law Review 87.
    
     Suresh, H. / Guttag, J.V. (2019): A Framework for Understanding Unintended Consequences of Machine Learning. arXiv preprint arXiv:1901.10002.
    
     Underwood, T. (2019): Distant Horizons: Digital Evidence and Literary Change. University of Chicago Press.


