
            

                
Einleitung

                
Fotografien und andere Abbilder von Architektur dienen in vielen historischen Wissenschaften als Quelle und Grundlage für fach- und theoriespezifische Untersuchungen. So werden zum Beispiel historische Fotoaufnahmen herangezogen, um den Zustand eines Gebäudes zu rekonstruieren oder die Formensprache einer Epoche zu identifizieren. Ausgangspunkt dieser Szenarien aus Architektur-, Kunstgeschichte und Kulturwissenschaften ist eine durch Hilfsmittel der jeweiligen Fächer unterstützte Quellenrecherche und -kritik, auf die weitere Auswertungen und Verwendungen im wissenschaftlichen Kontext aufbauen.

                
Obwohl sich KI-basierte Methoden der 
                    
Computer Vision
 in den letzten Jahren wesentlich weiterentwickelt haben, können diese den Prozess der Quellenrecherche und -kritik bisher allenfalls im Ansatz unterstützen, bspw. für die Exploration von Bildrepositorien oder das Retrieval von Bildern. Dies liegt zum einen daran, dass elementare diesbezügliche Vorgehensweisen zwar gut dokumentiert sind, WissenschaftlerInnen aber sehr individuell vorgehen. Zum anderen ist KI-Bildverarbeitung bisher wenig darauf ausgelegt, bildliche Inhalte multimodal zu kontextualisieren, d.h. verschiedene Quellengattungen wie Bilder und Texte zu kombinieren. Existierende Verfahren der Computer Vision extrahieren rein visuelle Merkmale und klassifizieren diese, während Texte oder Metadaten und darin enthaltenes Wissen wie bspw. Hinweise auf zeitliche Kontexte oder einzelne Motive nicht mit der Analyse verknüpft werden können.
                

                
Das BMBF-geförderte Projekt 
                    
HistKI
 startete im Januar 2021 und will die Unterstützung und Modellierung von Bildquellenrecherche und -kritik als komplexe und grundlegende geschichtswissenschaftliche Arbeitstechnik durch multimodale KI-basierte Verfahren erforschen. Damit verbundene Teilfragen sind beispielsweise: Wie finden und beurteilen Historiker und andere Fachwissenschaftler Bildquellen? Welche generischen Vorgehensweisen und Teilproblemstellungen lassen sich hierfür identifizieren? Wie lässt sich dies mit KI-basierten Ansätzen befördern? Wie wirken sich KI-Techniken auf den geisteswissenschaftlichen Forschungsprozess aus? 
                

            

            

                
Forschungsstand

                
Ausgangspunkt des Vorhabens ist der geschichtswissenschaftliche Forschungsprozess im Umgang mit Bildquellen. Für ein forschendes Handeln in den historischen Wissenschaften prägend sind einzelne Themenfelder (bspw. Kunst, Technik, Wirtschaft, Politik) sowie die darauf bezogenen Erkenntniszugänge. Leitendes Paradigma ist eine konstruktivistische Problemorientierung und damit eine quellenkritische, gegenstandsbezogene Analyse (Wengenroth, 1998, Reich, 2006). Methodologische Zugänge dazu liefern bspw. Hermeneutik, Semiotik (Holenstein, 1988, Zöllner, 2005) oder Phänomenologie (Prechtl, 2002). Grundsätzlich findet ein Zugang über Quellen statt und die damit verbundene Quellenkritik ist eine grundlegende Vorgehensweise historischer Forschung (Opgenoorth, 1997).

                

                    
Modellierung forschenden Handelns
: Eine Systematisierung von digitalem Forschungshandeln in den historischen Wissenschaften erfolgt bspw. aus Perspektive der eScience (Köhler et al., 2016) oder Informationswissenschaften, Ansätze zur Modellierung von Prozessabfolgen forschenden Handelns sind bspw. Forschungsprimitive (Münster and Terras, 2020, Kamposiori and Benardou, 2011). Demgegenüber stehen Ansätze zur sozialwissenschaftlichen Analyse des Informations- und Forschungsverhaltens (Münster et al., 2018, Ying et al., unpublished), bspw. der Science and Technology Studies (STS) u. a. anhand epistemischer Kulturen (Knorr-Cetina and Reichmann, 2015) oder der Wissenschaftsphilosophie anhand der Erkenntnisprozesse (Fleck, 1980, Popper, 1998). Damit gehen Ansätze zur Operationalisierung einerseits von der (1) „mechanistischen“ Idee aus, forschendes Handeln als Abfolge von operationalisierbaren Forschungsschritten (e.g. Forschungsprimitive, eScience) zu betrachten. Andererseits steht (2) die Vorstellung eines geisteswissenschaftlichen Forschungshandelns als „Black Box“ und erfahrungsbasiert, auf implizitem Wissen (Polanyi, 1966) basierend sowie der Wissensgenese als „serendipity“ (e.g. STS). Nicht zuletzt hinsichtlich der Lehrbarkeit haben sich in den bildbezogenen historischen Wissenschaften (3) semi-operationalisierte Zwischenformen etabliert – bspw. die bereits benannte Quellenkritik sowie speziell für Bildmedien die ikonologische Analyse (Panofsky, 1939). Trotz derartiger systematisierender Ansätze erfolgt eine Recherche und kritische Betrachtung von historischen Quellen in der Praxis hochgradig individuell und erfahrungsbasiert (Brieber et al., 2014, Münster et al., 2018). Vor diesem Hintergrund werden KI-basierte Ansätze derzeit vor allem zur Unterstützung von abgegrenzten Teilproblemen, wie Suche nach ähnlichen Bildern (Münster et al., 2019, Bell and Ommer, 2019), die Anreicherung von textuellen Metadaten (Lee and Münster, 2018) sowie Musteranalyse (Kohle, 2018, Klinke, 2016), eingesetzt.
                

                

                    
Bildwissenschaftliche Zugänge:
 Eine Reihe von aktuellen Publikationen und Initiativen greifen das Zusammenspiel von bildbezogenen historischen Wissenschaften und KI-basierten Forschungsansätzen auf – bspw. der Band „Digital Art History“ (Kuroczynski et al., 2019) sowie das DFG-Schwerpunktprogramm „Das digitale Bild“ (Kohle, 2018). Trotz heterogener Ansätze zur Bildrecherche und Quellenkritik existiert eine Reihe allgemeiner Problemstellungen (Hoppe and Breitling, 2016). HistKI liefert mit seiner inhaltsgetriebenen und forschungsprozessorientierten Fragestellung eine wichtige und komplementäre Grundlage für diese Initiative.
                

                

                    
Language &amp; Vision:
 Neuere Ansätze der Bildverarbeitung aus dem Bereich des Deep Learning ermöglichen nicht nur eine bessere Objekterkennung, sondern erweisen sich als besonders geeignet für 
                    
transfer learning 
an der Schnittstelle von Bild- und Sprachverarbeitung. Dabei werden zum Beispiel semantische Repräsentationen wie 
                    
word
 oder 
                    
sentence embeddings
, die aus Texten gelernt werden, anhand von multimodalen Daten wie Bildbeschreibungen mit visuellen Repräsentationen angereichert. Damit ist das Vokabular eines Objekterkennungssystems aus der Bildverarbeitung, das typischerweise auf eine mehr oder weniger große Menge an Kategorien festgelegt ist, wesentlich erweitert und es können semantische Bezüge zwischen visuellen Objekten und einer großen Menge an Wörtern oder Phrasen erfasst werden. Beispielsweise gibt es aktuelle Untersuchungen zur automatischen Erkennung eines inhaltlichen Bezugs zwischen Bildern und Textpassagen, (Hessel et al., 2019). Diese Art von Modellierung stellt einen Schritt in Richtung der Herstellung eines gemeinsamen Kontexts von Bild und Text dar. Für die multimodale Extraktion von Informationen aus fachwissenschaftlichen Texten ist es jedoch notwendig, solche referentiellen Beziehungen zwischen Text- und Bild-Teilen auch feingliedriger zu erfassen (Utescher and Zarrieß, 2021).
                

                

                    
Segmentierung und Objekterkennung:
 Die Grundlagen für die Rekonstruktion aus historischen Fotografien bilden die analytischen Verfahren der Photogrammetrie, d.h. die Gewinnung zwei- und dreidimensionaler Objektgeometrien aus den zweidimensionalen Bildinformationen (Wiedemann et al., 2000). Photogrammetrische Verfahren liefern auch räumliche Relationen zwischen Fotografien und dreidimensionalen Objektgeometrien. Aus durch bildgebende Verfahren entstandenen Datensätzen lassen sich einfache Strukturen (Vosselman et al., 2004), aber auch komplexe Objekte wie Gebäude (Li et al., 2016, Agarwal et al., 2011) automatisch segmentieren sowie zuordnen (Martinovic et al., 2015, Hackel et al., 2016). Dabei können auch Rückschlüsse darauf gezogen werden, welche Bildteile welche Teile der 3D-Objektgeometrien referenzieren (Xie et al., 2016, Vosselman et al., 2004). Maschinelles Lernen (ML) spielt eine zunehmend größere Rolle bei der Segmentierung von Bild und der Objekterkennung (Minaee et al., 2021, Jiao et al., 2019) sowie der Strukturerkennung in 3D-Daten (Guo et al., 2020). Insbesondere vor dem Hintergrund der Anwendung von ML Ansätzen auf historische Quellen bestehen spezifische Herausforderungen in zumeist sehr kleinen und qualitativ heterogenen Ausgangsdaten (Fiorucci et al., 2020).
                

                

                    
Verortung und Exploration:
 Ein besonderes Verhältnis besteht zwischen Bildquellen und 3D-Modellen. Im BMBF-Projekt 
                    
HistStadt4D
 wurden exemplarisch Methoden zur automatischen Verortung von Fotografien entwickelt (Maiwald and Maas, 2021) und diese Daten in einer virtuellen 4D-Forschungsumgebung zugänglich gemacht (Bruschke et al., 2018, Maiwald et al., 2019) sowie quantitative raumbezogene Analysemethoden evaluiert (Dewitz et al., 2019). Mit Hilfe von Verfahren des maschinellen Lernens sollen in 
                    
HistKI
 zudem Objektquellen und Textquellen (z.B. Bildunterschriften) verknüpft werden, um in Zukunft eine detaillierte Kontextualisierung und Verortung der Fotografien und Texte zu erlauben und damit über bisherige Methoden des 
                    
distant viewing
 (Arnold and Tilton, 2019) hinauszugehen.
                

            

            

                
Forschungsaufriss

                
Im Folgenden soll ein kurzer Überblick über erste Forschungsschritte im Projekt gegeben werden.

                

                    

                    
Abb. 1: Identifizierte Architekturelemente im Bild (links), im Text (mitte) und im 3D-Modell (rechts) am Beispiel des Kronentors des Dresdner Zwingers.

                

            

            

                
Identifikation von Forschungsszenarien

                
Der Einsatz von multimodalen KI-Techniken wird anhand von ausgewählten Szenarien untersucht, in denen Informationen aus Bildern, Texten und 3D-Modellen zur Beschreibung von Wissen über Architekturobjekte und städtebaulichen Ensembles für einen Analyseprozess mit¬einander verschränkt werden können. In Voruntersuchungen wurde dafür mit Hilfe qualitativer Expertenbefragungen und Workshops eine Reihe generischer Szenarien identifiziert (Kröber, 2021, Dewitz et al., 2019) und hinsichtlich einer Relevanz und Umsetzbarkeit priorisiert. Aus den ermittelten ca. 20 Szenarien wurden für eine erste Projektphase die medienübergreifende Identifikation von Objektbeschreibungen („Welche Bilder, Texte, 3D-Daten beschreiben dasselbe Objekt?“) sowie die Analyse von Beschreibungen (bspw.: „Wie kann die Datierung von historischen Bild- und Textdarstellungen von Objekten durch eine multimodale Validierung, bspw. anhand bereits datierter Medien, unterstützt werden?“) als Forschungsschwerpunkte ausgewählt.

            

            

                
Medienübergreifende Klassifikation

                
Die medienübergreifende Verarbeitung von 3D-Modellen, Bild- und Textquellen in einem möglichst universellen Format ist eine der zentralen Herausforderungen des Projekts. Eine diesbezüglich wichtige Voraussetzung ist es, medienübergreifend Elemente zu identifizieren und zu benennen. Die Entwicklung von domänenspezifischen Ontologien für architekturgeschichtliche Inhalte ist aktuell ein Schwerpunktthemen und wird von einer Vielzahl von Initiativen vorangebracht – beispielhaft seien hier ICONCLASS
, Getty Art &amp; Architecture Thesaurus (AAT), als generische Ontologie Wikibase
 sowie als übergreifende Referenzontologie CIDOC-CRM benannt. Als Grundgerüst für die strukturierende Beschreibung von Architekturelementen dient in unserem Projekt das AAT, welches trotz aktuell noch vorhandener Defizite hinsichtlich der deutschen Übersetzung durch eine umfassende und an einer kunsthistorischen Typisierung orientierte Struktur eine gute Ausgangsbasis für unser Projekt verspricht. Dabei wird von uns zunächst nur die gemessen am Gesamtvokabular kleine Untergruppe 
                    
architectural elements
 verwendet. Die identifizierten Elemente im Text (einzelne Wörter oder Wortgruppen), Bild (polygonale Bildausschnitte) und 3D-Modell (einzelne Teilgruppenobjekte) werden den Konzepten des AAT zugeordnet (Abb. 1). Je nach Quellentyp sind dabei verschiedene Verfahren, wie z.B. semantic segmentation, named entity recognition (NER), und discourse parsing, notwendig, sowohl was die Identifizierung der Konzepte als auch die semantische Anreicherung betrifft. Als Nächstes müssen die identifizierten Konzepte zwischen den verschiedenen Quellen in einen Zusammenhang gebracht werden. Dazu werden die Identifier der AAT-Konzepte abgeglichen sowie meta-klassifiziert (z.B. Ionische Säule 
→
 Säule). Um mehrere Instanzen einer solchen Klasse zu unterscheiden (bspw. einzelne Säulen in einer Säulenreihe) werden die einzelnen Instanzen mit einer Identifikationsnummer versehen. Das AAT liefert ein detailliertes Vokabular zur Klassifizierung, reicht aber derzeit nicht aus, um alle Informationen, insbesondere Informationen aus Textquellen, vollständig abzubilden. Es müssen daher weitere Merkmale identifiziert werden, die das AAT nicht repräsentieren kann, wie z.B. Lagebeziehungen („Ostflügel“, „Westfassade“) oder Eigennamen.
                

            

            

                
Multimodale Datenanreicherung

                
In einem weiteren Schritt werden Ansätze zur multimodalen Datenanreicherung und -validierung entwickelt. So werden beispielsweise im 3D-Raum in Relation zum 3D-Modell verortete Bilder verwendet, um eine im 3D-Modell vorliegende Strukturierung auf Bilddokumente zu übertragen (Niebling et al., 2018). Durch den räumlichen Zusammenhang zwischen Bild und Modell können Annotationen von bereits semantisch angereicherten 3D-Modellen bzw. ihrer einzelnen Bauteile auf die entsprechenden Bildquellen projiziert, sowie auch von bereits annotierten Bildquellen auf 3D-Modelle zurückübertragen werden. Der 3D-Raum bietet zudem erweiterte Möglichkeiten, Lagebeziehungen zwischen (Teil-)Objekten herauszufinden. Die erkannten Zusammenhänge und semantischen Beziehungen werden in einer Ontologie gespeichert.

            

            

                
Ausblick

                
Quo vadis? Während im aktuellen Projektstadium mit manuell klassifizierten Quellen gearbeitet wird, ist ein nächster Schritt ist die Untersuchung von Ansätzen zur automatisierten Erkennung und Annotation von Objektbestandteilen. Hier werden schwerpunktmäßig KI-basierte Modelle verwendet, die auf die jeweiligen Modalitäten (3D-Modelle, Bilder, (multimodale) Texte) spezialisiert sind – beispielsweise die bereits benannten computerlinguistischen Verfahren zur Texterkennung sowie ein modulares Object Retrieval für die Erkennung von architektonischen Strukturen in Bildern (Münster et al., in print) und die in Schritt 3 ausgeführte Übertragung dieser Segmentierung auf 3D-Modelle.

                
Darauf aufbauend erfolgen in weiteren zukünftigen Schritten einerseits die Verbesserung und multimodale Validierung von Erkennungsqualitäten sowie die Entwicklung eines Demonstrators zur Nutzererprobung mit Historiker*innen.

                
Dies dient auch als Grundlage einer Bewertung von KI-Ansätzen für die historische Forschung. Hier gilt es beispielsweise, die Diskrepanz zwischen dem großen Datenbedarf der KI-Modelle und der Komplexität des geschichtswissenschaftlichen Expertenwissens zu untersuchen und damit zu bewerten, wie effektiv existierende KI-Modelle mit begrenzten Datenmengen für Teilaspekte der (architektur-)geschichtlichen Quellenkritik eingesetzt werden können.

            

        
