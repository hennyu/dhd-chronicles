
                        Bereits 2017 veröffentlichte Douglas Duhaime über das Yale Digital Humanities Lab eine Visualisierung für das Clustering von Bilddaten im hochdimensionalen Featureraum. Verfügbar unter: 
                        
                            https://dhlab.yale.edu/projects/pixplot/
                        
                        .
                    
                        Ein digitales Research-Werkzeug, mit dessen Hilfe große Bilddatenmengen in den Geisteswissenschaften nutzbar gemacht werden sollen. Ein DFG-Projekt der Ludwig-Maximilians-Universität München, der Technischen Informationsbibliothek Hannover sowie des Heinz-Nixdorf-Instituts. Erreichbar unter: 
                        
                            https://www.iart.vision/
                        
                        .
                    
                        Eine visuelle Suchmaschine für die digitale Kunstgeschichte, die auf Embeddings neuronaler Netzwerke basiert. Entwickelt von Fabian Offert mit Unterstützung von Peter Bell und Oleg Harlamov. Abrufbar unter: 
                        
                            https://imgs.ai/
                        
                        .
                    
                        Ein Proof of Concept ist veröffentlicht unter: 
                        
                            https://github.com/DominikBoenisch/Training-the-Archive
                        
                        . Ein weiterer Prototyp kann über die RWTH Aachen University genutzt werden: 
                        
                            https://vci.rwth-aachen.de/annotation-tool/
                        
                        .
                    
                        ARTigo ist ein Forschungsprojekt der Ludwig-Maximilians-Universität München, welches mittels Crowdsourcing über ein Online-Spiel das Ziel verfolgt, Kunstwerke mit Tags zu versehen und durch Schlagworte zu beschreiben. Siehe: 
                        
                            http://www.artigo.org
                        
                        .
                    
            
                
                    Bibliographie
                    
                        Bell, Peter / Ommer, Björn 
                        (2016): "Visuelle Erschließung. Computer Vision als Arbeits- und Vermittlungstool", in: 
                        Konferenzband EVA Berlin 2016. 
                        Elektronische Medien & Kunst, Kultur und Historie. EVA Berlin, Band 23. Heidelberg: arthistoricum.net 67-73.
                    
                    
                        Bönisch, Dominik
                         (2021): "The Curator’s Machine: Clustering of Museum Collection Data through Annotation of Hidden Connection Patterns Between Artworks", in: 
                        International Journal for Digital Art History
                        , 5 (Mai): 5.20-5.35. doi:10.11588/dah.2020.5.75953.
                    
                    
                        Brüggemann, Viktoria / Kreiseler, Sarah / Dörk, Marian
                         (2016): "Museale Bestände im Web: Eine Untersuchung von acht digitalen Sammlungen", in: 
                        Konferenzband EVA Berlin 2016. 
                        Elektronische Medien & Kunst, Kultur und Historie. EVA Berlin, Band 23. Heidelberg: arthistoricum.net 227-236.
                    
                    
                        Glinka, Katrin / Dörk, Marian
                         (2018): "Zwischen Repräsentation und Rezeption – Visualisierung als Facette von Analyse und Argumentation in der Kunstgeschichte", in: 
                        Computing Art Reader: Einführung in die digitale Kunstgeschichte
                        . Computing in Art and Architecture, Band 1. Heidelberg: arthistoricum.net 234-250.
                    
                    
                        Hunger, Francis
                         (2021a): "
                        Why so many windows?
                        "
                         – Wie die Bilddatensammlung ImageNet die automatisierte Bilderkennung historischer Bilder beeinflusst
                        . Training the Archive – Working Paper, Aachen/Dortmund, Juni. doi:10.5281/zenodo.4742621.
                    
                    
                        Hunger, Francis
                         (2021b):
                        Kuratieren und dessen statistische Automatisierung mittels Künstlicher 'Intelligenz'.
                        Training the Archive – Working Paper, Aachen/Dortmund, Oktober. doi:10.5281/zenodo.5589930.
                    
                    
                        Radford, Alec / Kim, Jong Wook / Hallacy, Chris / Ramesh, Aditya / Goh, Gabriel / Agarwal, Sandhini / Sastry, Girish / Askell, Amanda / Mishkin, Pamela / Clark, Jack / Krueger, Gretchen / Sutskever, Ilya
                         (2021): "
                        Learning Transferable Visual Models from Natural Language Supervision
                        ", in: 
                        arXiv preprint.
                         arxiv:2103.00020.
                    
                    
                        Saglani, Vatsal
                         (2021): "What is CLIP (Contrastive Language – Image Pre-training) and how can it be used for semantic image search?", 
                        Towards AI
                        , 9. Februar https://pub.towardsai.net/what-is-clip-contrastive-language-image-pre-training-and-how-it-can-be-used-for-semantic-image-b02ccf49414e [letzter Zugriff 22.11.2021].
                    
                
            
        