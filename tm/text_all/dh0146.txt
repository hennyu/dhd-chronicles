
            
                Einleitung
                Zeitschriften und Zeitungen aus den verschiedenen historischen Epochen und Ländern werden seit Jahren digitalisiert und der Öffentlichkeit und Forschung zugänglich gemacht. Allein im europäischen Raum gibt es dazu groß angelegte Projekte, die untereinander z.T. eng vernetzt sind (Europeana, ANNO, The British Newspaper Archive, Delpher, Gallica, Hemeroteca digital, ZDB, ZEFYS). Diese Erzeugung neuer Forschungsdaten bzw. das Zugänglichmachen von bisher auf der ganzen Welt verstreuter kultureller Zeitzeugen wirft für sich allein genommen bereits eine Reihe praktischer und theoretischer Fragen auf. Da die meisten Digitalisierungsprojekte von Bibliotheken initiiert werden, herrschen zumindest in der Art und Weise der Erstellung und Verwaltung gewisse Standards vor (DFG 2013). Die Einigung auf ein Dateiformat, in dem die Zeitungen und Zeitschriften präsentiert werden oder welche Zugriffsrechte bestehen, scheint aber dennoch schwierig zu sein. Wenn sich Forschende ein Zeitungs- oder Zeitschriftenkorpus zusammenstellen, dann gehen sie zumeist eine Kooperation mit der besitzenden Bibliothek ein oder verfügen selbst über die Rechte an der Sammlung (vgl. dazu DH-Projekte wie: Oceanic Exchanges, illustrierte magazine, Die Fackel, Chinese Entertainment Newspapers, Chinese Women's Magazines, WeChangEd, Blue Mountain, MJP, MMP, Revistas Culturales 2.0, Journalliteratur, Literatur im Zeitalter der Illustrierten, u.v.m.). Es stellen sich schon bei der Datenerzeugung eine Reihe von Fragen, deren Klärung zu einer vereinfachten Zugänglichkeit der Forschungsdaten und -objekte führen würde (vgl. Panelbeiträge Neudecker, Kampkaspar/Resch).
                Daneben sind Zeitungen und Zeitschriften als Medien per se multimodal (Igl / Menzel 2016; Fricke 2012) und -medial konzipiert. Sie setzen sich aus Bild-Text-Arrangements zusammen und nutzen verschiedene Modalitäten (Interaktion versch. Codes im selben Medium) zur Kommunikation. Da Zeitungen und Zeitschriften in verschiedene Bereiche untergliedert sind, verlangen sie von Leser*innen einen anderen Lektüremodus als das Buch, der Brief, das Plakat, das Comic oder andere Druckwerke. Dabei können sie aber selbst diese anderen Medien enthalten und abbilden. Gerade die Mischung der Formate und Inhalte zeichnet das Medium aus und definiert Sub-Genres (Tages- oder Wochenzeitung, Sport- oder Kulturzeitschrift). Zusätzlich zur schlichten Menge der Inhalte, kommt normalerweise auch ein Layout, das sich von anderen Druckwerken unterscheidet. Bei Zeitungen sind es zumeist Kolonnen, bei Zeitschriften können es auch buchähnliche Aufteilungen sein, die sich zudem im Laufe der Entwicklung vom 17.-21. Jahrhundert verändern (Rißler-Pipka 2017). All diese Merkmale, die hier nur angerissen werden können, bescheren uns beim Wechsel vom analogen Druckwerk zum Digitalisat eine Reihe von Herausforderungen – sowohl theoretischer als auch technischer Art. Von theoretischer Perspektive aus behaupten wir, historische Brüche und Veränderung anhand multimodaler Wahrnehmung diagnostizieren zu können. Das geht einher mit der von Walter Benjamin beschriebenen technischen Reproduzierbarkeit des Kunstwerks (Benjamin 1935-39) und reicht bis zu aktuell kritischen Beobachtungen aus Lateinamerika, die die Rezeption der modernen Presse und Zeitschriften mit der Nutzung digitaler Medien vergleichen (Macciuci 2015: 209). Aus technischer Perspektive stellt sich zum einen das Problem der Texterkennung auf Artikelebene (OCR, NewsEye). Zum anderen gilt es zu überlegen, wie man diese Besonderheiten des Artefakts Zeitung oder Zeitschrift ins digitale Forschungsobjekt überträgt (Drucker 2009: 109; Gooding 2017: 173). Nicht nur die Lesesituation wird eine andere sein, ob das Werk aus Papier im Kaffeehaus gelesen wird oder ob es am Bildschirm digital geblättert oder als XML-Datei dargestellt wird. Auf der anderen Seite gibt es Sorgen um den Verlust der Materialität, der Haptik, der multimodalen Wahrnehmung. Dazu haben sich schon lange vor der Digitalisierung eigene Theorien gebildet (Gumbrecht et al. 1995; Genz / Gévaudan 2016). Niemand möchte ernsthaft ein Äquivalent zum Artefakt finden, aber es sollte auf der anderen Seite die Flexibilität und Interoperabilität bestehen, um sowohl die Anforderungen von FAIR (Wilkinson et al.) als auch diejenigen der Forschung zu erfüllen. Entsprechend der vorgestellten Beiträge sollen gemeinsame Fragen diskutiert werden wie: 
                
                    Welche für die Forschung relevanten Elemente werden im digitalen Forschungsobjekt repräsentiert? 
                    Wie können die Daten und Metadaten für die Analyse genutzt werden? 
                    Welche Metadatenstandards werden aktuell international verwendet und welche Probleme könnten damit gelöst werden? 
                    Wie verändert sich die Forschung und ihre Fragestellungen durch die Arbeit am digitalen Forschungsobjekt?
                    Kann die Multimodalität des Forschungsobjekts durch digitale Methoden analysiert werden oder wird das Nebeneinander eher verstärkt (Podewski 2018)?
                
                Die Panelvorträge zeigen verschiedene Seiten aus den Bereichen der Digitalisierung und Bereitstellung (1-2) sowie der späteren Analyse (3-4), um so anhand konkreter Beispiele aus der Praxis die Diskussion anzustoßen.
            
            
                 Panelvorträge
                
                    Masse vs Klasse oder (wie) lässt sich die Dynamik von Digitalisierung und Digital Humanities organisieren? (Clemens Neudecker)
                    Die Zeitungsdigitalisierung wurde in Deutschland im internationalen Vergleich lange Zeit vernachlässigt. Vom DFG-Pilotprojekt zur Digitalisierung historischer Zeitungen wurde 2016 ein Master-Plan vorgelegt, dem neben einer DFG-Ausschreibung zur Massendigitalisierung von Zeitungen auch ein Projekt zur Errichtung eines nationalen Zeitungsportals innerhalb der Deutschen Digitalen Bibliothek (DDB) folgte. Das Ziel dieser Initiativen ist es, in den kommenden Jahren eine maßgebliche Erhöhung der digitalisierten Zeitungen in Deutschland und deren zentralen Nachweis für die Forschung zu ermöglichen. In Vorbereitung darauf wurde bereits die Zeitschriftendatenbank (ZDB) überarbeitet und bietet nun forschungsrelevante Mehrwertdienste wie u.a. die Visualisierung von Zeitungsnetzwerken. Aber auch auf europäischer (Europeana Newspapers) und internationaler Ebene finden Bemühungen statt, die zum Ziel haben, Suche und Analyse für digitalisierte Zeitungen über Sprach- und Landesgrenzen hinaus zu vereinfachen. Parallel dazu sind zahlreiche Digital Humanities Projekte entstanden (Oceanic Exchanges, impresso, NewsEye) die mit unterschiedlichen Verfahren und Forschungsdesigns an umfangreichen Zeitungskorpora arbeiten. Die Interoperabilität von Datenmodellen spielt dabei für die Digital Humanities eine ebenso große Rolle wie die Möglichkeit, zusätzliche durch Analyse und Annotation gewonnene Informationen zu vorhandenen Metadaten hinzuzufügen. Andererseits stoßen auch die im Zuge der Digitalisierung entstehenden Metadaten zur Provenienz auf zunehmendes Interesse bei Forschenden. Vor diesem Hintergrund stellt sich die Frage, wie sich die Dynamiken von (Massen-)Digitalisierung und spezifischen Anforderungen der diversen Forschungsvorhaben in Einklang bringen lassen und inwieweit hierbei neue Technologien wie IIIF und das W3C Web Annotation Data Model von Nutzen sein können.
                
                
                    Die Wiener Zeitung als Fallstudie: Partizipative Ansätze in der Praxis (Dario Kampkaspar / Claudia Resch )
                    Wie sich historische Zeitungen vom analogen Druckwerk in digitale Medien überführen lassen, wird derzeit am Beispiel der ältesten, bestehenden Zeitung der Welt, der Wiener Zeitung (im 18. Jahrhundert: "Wien(n)erisches Diarium") an der Österreichischen Akademie der Wissenschaften erprobt. Das Projektteam nutzt die Plattform "Transkribus", um aus mehreren Hundert historischen (Frakturtext-) Ausgaben, die derzeit im Portal ANNO als Bild-Digitalisate vorliegen, verlässliche Volltexte zu generieren und diese schrittweise online zur Verfügung zu stellen. Am Beispiel des Projekts soll gezeigt werden, wie gemeinsam mit künftigen User*innen im Rahmen der technischen Möglichkeiten eine Benutzeroberfläche entwickelt wird. In diesem Zusammenhang wird das Projektteam seine aktuelle Umfrage unter Forschenden, die mit der Zeitung vertraut sind und häufig mit ihr arbeiten, vorstellen. Denn je konkreter die individuellen Interessen der zukünftigen Zielgruppen am Datenmaterial formuliert sind, desto besser lässt sich einschätzen, worin die Herausforderungen bei der Digitalisierung historischer Zeitungs- und Zeitschriftenbestände in Zukunft liegen (vgl. Gooding 2017: 172).
                
                
                    Kulturzeitschriften als soziokulturelle Produkte (Teresa Herzgsell / Jörg Lehmann)
                    Im DFG-Projekt "Literarische Modernisierungsprozesse und transnationale Netzwerkbildung im Medium der Kulturzeitschrift" werden Metadaten zu Kulturzeitschriften manuell erhoben und in ein feingliedriges Klassifikationssystem eingeordnet: Name des/der Beiträger*in (nebst Geschlecht, Herkunftsland, etc.), Pseudonyme, Titel, Genre und Sprache des Beitrags. Gegebenenfalls werden auch Widmungen, Erstpublikation, Originalsprache, etc. erfasst. Gegen Ende des Projekts werden fast 60 spanischsprachige Kulturzeitschriften ausgewertet sein. Diese umfangreiche Datensammlung bildet die Grundlage für die Analyse der Akteurs- und Genrenetzwerke (Ehrlicher / Herzgsell 2016). Sie bietet aber auch die Möglichkeit, statistische Auswertungen der erhobenen Merkmale der Zeitschriften sowie der Beiträger*innen durchzuführen. 
                    Um Zeitschriften als soziokulturelle Produkte zu charakterisieren, präsentieren wir in unserem Beitrag Auswertungen relevanter Metadaten. Unser Anliegen ist es, auf einer quantitativen Grundlage sichtbar zu machen, wie die Zeitschriften aufgemacht sind und wie die soziodemographischen Daten zu den Beiträger*innen diese Aufmachung konfigurieren. Wir wollen folgenden Forschungsfragen nachgehen: Inwiefern können die manuell erhobenen Daten – wie etwa die verwendeten Genreklassifikationen und die Titel der Beiträge – Auskunft geben über das Profil der Zeitschriften? Lassen sich die verschiedenen Zeitschriften auf Grundlage dieser Merkmalskombinationen in Gruppen mehr oder weniger ähnlicher Kulturprodukte unterteilen? Kann man auf statistischer Basis Vorlieben bestimmter Beiträger*innen für bestimmte Text- und Bildformen ausmachen, d.h. Autor*in-Genre-Korrespondenzen? Lassen sich Korrelationen zwischen den verwendeten Genres und den biografischen Daten der Beiträger*innen finden?
                
                
                    Forschen mit Metadaten: Über notwendige und zusätzliche Metadaten in Zeitungs- und Zeitschriftenprojekten (Nanette Rißler-Pipka)
                    Was bezeichnen wir überhaupt als Metadaten von Zeitungen und Zeitschriften und welchen Mehrwert haben sie für die Forschung?
                     Von Seiten der Literaturwissenschaft wird das Desiderat der Forschung bezüglich fehlender (Meta-)Daten, die es ermöglichen Zeitungen und Zeitschriften als kulturelle Zeitzeugen in Beziehung zu setzen, schon von Frank et al. genau bestimmt, (Frank et al.: 2010, 10). Es wird dort gefragt, wer wo über wen und aus welcher Perspektive geschrieben habe. Teilweise lässt sich dies mit bibliographischen Metadaten oder denjenigen aus Inhaltsverzeichnissen quantitativ ermessen. Teilweise müssen aber auch je nach Forschungsfrage Metadaten in Form von Annotationen hinzu gefügt werden. Der Fokus soll hier auf die Interoperabilität der Metadaten gelegt werden, d.h. wie werden sie angelegt? Dies zielt auf die Frage ab, welche theoretischen Vorüberlegungen für die Entwicklung einheitlicher Metadatenstandards speziell in dem Bereich der Zeitungen- und Zeitschriftenforschung notwendig sind. Neben den händisch angelegten Metadaten kommen in einem digitalen Analyseworkflow meist auch Ergebnisse aus Tools hinzu, die auch als Metadaten des digitalen Forschungsobjekts behandelt werden und im Idealfall gemeinsam mit den vorhandenen Metadaten ausgewertet werden sollten.
                
            
        