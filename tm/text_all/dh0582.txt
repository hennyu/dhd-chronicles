
            
                Ausgangslage
                Getrieben von einer fortschreitenden Computerisierung ihrer wissenschaftlichen Methodik und einer wachsenden Verfügbarkeit von digitalen Bildwerken ist in den letzten Dekaden in zahlreichen Disziplinen der Geistes- und Kulturwissenschaften ein erneuertes Interesse am Bild als Forschungsgegenstand und Erkenntnisinstrument zu beobachten. 
                So begreift sich etwa die (digitale) Kunstgeschichte in der Erweiterung explizit als digitale Bildwissenschaft (Kohle 2013), hat die Geschichtswissenschaft als “Visual History” das lange vernachlässigte Medium Bild als Quellengattung neben dem Text wiederentdeckt (Paul 2014), erfindet sich die Architekturgeschichte nicht zuletzt mit digitalen Instrumenten als Disziplin neu und haben sich junge Fächer wie die Material-Culture-Studies oder die Designgeschichte etabliert.
                Alle diese Disziplinen begegnen sich in den Digital Humanities als einem geteilten Wissensraum, dessen Erkundung ganz wesentlich von den Möglichkeiten der Informatik mitbestimmt wird.
                Die automatisierte Erschließung großer und größter Bildkorpora im Sinne eines effektiven Information Retrieval prägt dabei nach Jeffrey Schnapp die erste Welle der Digitalen Revolution (Schnapp 2011). Die zweite Welle - so wiederum Schnapp - müsse nun “qualitativ, interpretativ, erfahrungsbewusst, intuitiv erfassbar und schöpferisch” sein, um digitale Instrumente in den Dienst der Kernkompetenzen der Geistes- und Kulturwissenschaften stellen zu können: Achtsamkeit gegenüber Komplexität, Medienspezifik, historischem Kontext, analytischer Tiefe, Kritik und Interpretation.
            
            
                
                    Ziele des Panels
                
                Mit dem hier vorgeschlagenen Panel verorten wir den Stand der digitalen Bildforschung in dieser idealtypischen Abfolge. Forschende aus unterschiedlichen Disziplinen beleuchten den State-of-the-art im Bereich automatisierter Verfahren der Computer Vision sowie gegenwärtige Wege und Visionen ihrer zukünftigen Anwendung in den Geistes- und Kulturwissenschaften. Wir erkunden Herausforderungen, die neue Werkzeuge wie die automatisierte Bildanalyse an Instrumentenkritik und Methodentransparenz stellen und tragen zur Konkretisierung von Best Practices in diesem Bereich bei.
            
            
                
                    Gegenstand
                
                
                    
                        Verfahren, Praktiken und Projekte
                    
                    Von Merkmalserkennung (Pattern Matching) bis hin zu Ansätzen aus dem Bereich des maschinellen Lernens wie etwa Deep Learning haben Verfahren der Computer Vision in den letzten Jahren das Potential entwickelt, sich als disruptive Technologie in den Geistes- und Kulturwissenschaften zu erweisen. Dieser Umstand verdankt sich unter anderem raschen Fortschritten bei der verfügbaren Rechenleistung, aber auch einem zunehmend vereinfachten Zugang zu geeigneter Software sowie einer wachsenden Verfügbarkeit digitaler Bilddaten.
                    Im Rahmen des Panels fragen wir zunächst nach den sich rasch entwickelnden Instrumenten und werfen einen Blick auf Bereiche und Projekte in denen diese zur Anwendung kommen. Wir wollen erkunden, welche Möglichkeiten computerbasierte automatisierte Verfahren etwa der Objekt- und Merkmalserkennung für die Digitalen Geisteswissenschaften eröffnen (zu einer einführenden Diskussion transdisziplinärer Potentiale von Computer Vision und Kunstgeschichte vgl. (Bell & Ommer (2015) sowie dies. (2016)). 
                
                
                    
                        Zwischen datengetriebenen und interpretativ hermeneutischen Zugängen
                    
                    Wir explorieren, ob und wie die anfangs postulierte Dichotomie von datengetriebenen und interpretativ-hermeneutischen Zugängen zur Generierung von Wissen (Drucker 2011) fortbesteht oder einem differenzierteren Modell Raum gegeben hat. Inwieweit lässt sich der am „Close Viewing“ geschulte Methodenapparat direkt auf Verfahren eines „Distant-Viewing“ (oder „Distant-Watching“ im Fall von Bewegtbildern) übertragen, oder inwieweit wird hier eine Wissenschaftstheorie des Digitalen noch zu entwickeln sein? Dies schließt die Frage einer adäquaten Instrumentenkritik ebenso ein, wie die nach Selektionsverfahren, Korpusbildung oder den Auswirkungen der Freigabepraxis von Bildmaterial durch Kulturinstinstitutionen (GLAM).
                
                
                    
                        Die semantische Lücke, Annotation, Multimodalität
                    
                    Die Analyse von “Big Image Data” auch im Bereich der Forschung wirft die Frage auf, wie Forschungsansätze in den letzten Jahren versucht haben, die “semantische Lücke” (Semantic Gap) im Umgang mit diesem Datenmaterial zu schließen.
                    Welche Rolle kommt etwa Normdaten (GND), Thesauri (ICONCLASS, AAT oder ULAN) oder Ontologien, die spezifisch für die Dokumentation kultureller Artefakte entwickelt wurden (CIDOC-CRM) bzw. Domäneontologien wie Neoclassica (Donig, Christoforaki, Handschuh 2016) zu?
                    Welche Rolle könnte alternativ die semantische Annotation (Oren, Möller, Scerri, Handschuh, & Sintek 2006) durch Zugänge etwa aus dem Bereich der Gamification und des Crowdsourcing wie in ARTIGO (Wieser, Bry, Bérard, Lagrange 2013) bieten? 
                    Kann die Informatik hier mit neuen Verfahren zur Verknüpfung verschiedener digitaler Analyseansätze in multimodalen Artefakten – also etwa die Untersuchung der Verbindung von Bild und Text oder Bewegtbild und Ton – digitales Sehen ergänzen und verbessern? (Bruni, Tran, Baroni 2014), (Hiippala 2013).
                
                
                    
                        Methodentransparenz & Best Practices
                    
                    In der Tat wirft ein digitales Sehen, analog zu kritischen Debatten um “Close” und “Distant Reading” (Bonfiglioli & Nanni 2015) grundlegende epistemologische Fragen nach den Gemeinsamkeiten oder Unterschieden zwischen computergestützter Bildanalyse und in spezifischen Praktiken des Sehens geschulten Menschen auf. Erweitert etwa der ferne Blick nur die Geschwindigkeit und Menge dessen, was wir wahrnehmen können, oder verändert er unsere Wahrnehmung selbst?
                    Wir erkunden wie digitale Instrumente beschaffen sein müssen, um den Erfordernissen der Geistes- und Kulturwissenschaften nach Methodentransparenz zu genügen. (Für eine grundsätzliche Diskussion der Konsequenzen des Designs von Klassifizierungs- und Rankingmechanismen sowie verschiedene Formen von Opacity siehe Burell 2016). Wie kann etwa der Black Box Charakter von Neuronalen Netzen sinnvoll akkommodiert werden? Nicht zuletzt stellt sich die Frage nach dem Zusammenspiel von Instrument und Forschungspraxis. Reproduziert etwa ein (in sich vollständig transparenter) Klassifikator, der aber auf der Basis eines bestimmten Korpus trainiert worden ist, nicht letztlich spezifische kulturelle Konzepte und konfirmiert damit einen bestehenden Kanon? 
                    Wir wollen uns diesen Fragen nicht verschließen, aber sie gleichermaßen rekontextualisieren wie über ihre forschungspraktischen Implikationen nachdenken. Wir werden dabei gerade mit jenen, die an der Weiterentwicklung dieser Instrumente arbeiten, diskutieren, wie Technologien gebaut und eingesetzt werden können, um ein emanzipatorisches und exploratives Potential zu entfalten. 
                    In diesem Sinn wollen wir abschließend Ideen für Best Practices im Sinne eines methodisch angeleiteten Umgangs mit großen Bildkorpora zusammentragen, indem wir etwa nach der Rolle und Modellierbarkeit von Kontextualisierung oder der Rolle von Ontologien und Normdaten dabei fragen.
                
            
            
                
                    Impulsvorträge
                
                
                    Siegfried Handschuh, Universität Passau: Bild, mutimodaler Verbund und Automatisierung
                    Bildanalyse stellt eine besondere Herausforderung an die Fähigkeit von computerbasierten Verfahren Wissen zu generieren. Dass Bilder vollkommen ohne einen Bezug zu anderen Modi – hier besonders Text – vorkommen ist eher eine Ausnahme als die Regel. Der multimodale Verbund von Bild und Text kann so durch Verfahren aus dem Bereich des maschinellen Lernens ausgewertet werden, um Wissen zu erzeugen, das einen breiteren Kontext berücksichtigt. Das Impulsstatement thematisiert diesen Zusammenhang insbesondere eine Methodik für die Repräsentation, Annotation und (teil)automatisierte Entdeckung multimodaler Wissensbestände in großen digitalen Materialkorpora und fragt wie Techniken der Computer Vision gewinnbringend mit Verfahren aus dem Bereich der Verarbeitung Natürlicher Sprache zusammengebracht werden können.
                
                
                    Canan Hastik, Technische Universität Darmstadt: Wie viel Semantik ist nötig und wie viel Automatisierung ist möglich?
                    Computerbasierte Verfahren sind ein wichtiges Instrument, um die digitale Bildforschung effizienter zu gestalten und zu verstetigen. Es wäre jedoch ein großer Fehler, Verfahren des maschinellen Lernens lediglich dafür einzusetzen, bestehende theoretische und historische Kategorien zu definieren und die Automatisierung für Digital Humanities Experten voranzutreiben. Die Herausforderung besteht darin, den DH Forscher bei der Kuration und Entwicklung von aussagekräftigen, repräsentativen und authentischen Forschungskorpora zu unterstützen. Ontologien sind dabei elementar für die Semantifizierung von großen bildbasierten Korpora und unterstützen zudem die kollaborative Entwicklung und die Verknüpfung von Wissensbeständen. Automatisierte Verfahren gilt es insbesondere dafür einzusetzen, zeitgenössische Kultur neu zu sehen und zu interpretieren. 
                
                
                    Hubertus Kohle, Ludwig-Maximilians-Universität München: Ähnlichkeitsbestimmung in der digitalen Kunstgeschichte
                    Das Statement widmet sich aus einer eher geisteswissenschaftlichen Perspektive heraus der digital gestützten Ähnlichkeitsbestimmung. Ähnlichkeit wird hier verstanden als Erkenntnismotor, der insbesondere in der Kunstgeschichte seinen Ort hat, die schon immer mit dem vergleichenden Sehen eine Methode des Erkenntisgewinns besaß. Abzuwägen wird sein, ob hierfür eher eine Metadatenanalyse oder die direkte Bildadressierung oder eine Mischung aus beidem zielführend ist.
                
                
                    Björn Ommer, HCI/IWR Ruprecht-Karls-Universität Heidelberg:
                    Aktuelle Entwicklungen im Bereich des Maschinellen Lernens und der Computer Vision haben Algorithmen hervorgebracht, die Visual Retrieval mit einer zuvor ungeahnten Performanz ermöglichen. Dadurch ergeben sich für die digitalen Bildwissenschaften ganz neue Möglichkeiten große Korpora zu erschließen und zu analysieren. Allerdings bringen diese neuen informatischen Verfahren auch ihre ganz eigenen Beschränkungen mit sich, die insbesondere bei ihrer Rekontextualisierung in den Geisteswissenschaften zutage treten. Dieser Vortrag wird das Potential einer interdisziplinären Kooperation von Informationswissenschaften und den Geisteswissenschaften diskutieren, grundlegende Beschränkungen beleuchten und mögliche Auswege präsentieren.
                
                
                    Malte Rehbein, Universität Passau: Moderation
                
            
        