
            
                
                    Einleitung
                
                Die wohl bedeutendste Struktur der zeitgenössischen akademischen Philosophie ist die Trennung zwischen kontinentaler und analytischer Philosophie.
                Obwohl wenig Einigkeit über die eigentliche Natur der Trennung besteht – ist es eine methodologische (vgl. Petrovich und Buonomo 2018), thematische, linguistische (vgl. Hobbs 2014), oder doch nur eine soziale? – spielt sie eine wichtige Rolle im philosophischen Berufsleben, und wird nicht nur informell verhandelt, sondern schlägt sich in den Aufnahmekriterien von Fachzeitschriften, in den Entscheidungen von Berufungskommissionen und im Aufbau zahlreicher professioneller Vereinigungen nieder.
                Klarheit über die Topologie dieser Trennung zu erreichen, ist dementsprechend von großem Interesse. Dennoch besteht in der Literatur eine ausgesprochene Uneinigkeit über eine Reihe von basalen Fragen: Wann hat die Spaltung ihren Anfang genommen (man vgl. die Darstellungen von e.g. Glock 2008; Critchley 1997; 2001)? Handelt es sich überhaupt um eine Trennung, oder eher um zwei Extreme am Rande eines Kontinuums? Hat sie überhaupt noch Bestand, oder hat sich die Kluft im einundzwanzigsten Jahrhundert weitestgehend geschlossen (Bieri 2007; Beckermann 2003; Hoche 2009)?
                
                    
                        
                        Zusammensetzung des gereinigten Datensatz über hundertzehn Jahre. Wir beobachten eine sich massiv verstärkende Dominanz des englischen Materials über das Jahrhundert hinweg, die Teils den Datenquellen geschuldet, zu einem großen Teil aber auch aus den Bedingungen des modernen wissenschaftlichen Publizierens erwachsen ist.
                    
                
                Diese Uneinigkeit ist nicht überraschend. Da die Konkretisierung der Trennung in eine Zeit exponentieller Zunahme des wissenschaftlichen Outputs seit den 1950er Jahren fiel (vgl. Bornmann und Mutz 2015, siehe auch Abb. 1), und zugleich von geografischen und sprachlichen Grenzen moderiert wurde, aber nicht mit diesen identifiziert werden kann, ist ihre Geschichtsschreibung mit außergewöhnlichen Herausforderungen konfrontiert, da sie sich nicht mit Hunderten, sondern eigentlich mit Hunderttausenden von heterogenen Quellen befassen muss, wenn sie Fragen nach der tatsächlichen disziplinären Meta-Struktur beantworten will, anstatt sich mit philosophischen Einzelschicksalen zu befassen.
                In der vorliegenden Arbeit schlagen wir eine Methode zur Beantwortung solcher grenzüberschreitenden, globalen Fragestellungen vor. Mithilfe eines multilingualen Sprachmodells (PhilroBERTa), welches wir auf philosophischen Texten fein-tunen generieren wir Textvektoren von 288.546 philosophischen Texten aus den vergangenen hundert Jahren. In dem derart aufgespannten Vektorraum identifizieren wir die Achse welche der kontinental-/-analytischen Unterscheidung entspricht. Indem wir die Positionierung der einzelnen Artikel auf dieser Achse erheben, können wir eine erste quantitative Einschätzungen der Topologie der analytisch/kontinentalen-Trennung vorschlagen.
            
            
                Datensatz
                Eine scharfe Umgrenzung des Gebietes der Philosophie, insbesondere eine, welche einem ganzen Jahrhundert und mehreren nationalen Philosophiekulturen, verpflichtet ist, ist ausgesprochen schwierig. Dementsprechend ist für die vorgelegte Arbeit der zugrundeliegende Datensatz so expansiv wie möglich gewählt worden. Der Datensatz enthält alle Texte welche in der JStor Datenbank unter der Rubrik ‘Philosophy’ archiviert worden sind (437.703 Rohtexte), sowie alle Abstracts aus dem 
                    Web of Science (WOS), welche in den Rubriken ‘Philosophy’ und ‘History and Philosophy of Science’ angesiedelt sind, oder aus in der 
                    PhilPapers-Journal-Liste verzeichneten Publikationen stammen (188.794 Einträge).
                
                
                    Da die Qualität der Rohdaten mäßig ist und die Fehlerquellen äußerst heterogen sind, verwenden wir einen Bulk-Labelling-Ansatz, bei dem alle Texte nach einem BOW-Modell encodiert werden und mit UMAP (McInnes, Healy, und Melville 2018)
                     
                    kartographiert werden. Cluster verwendbarer Rohdaten werden in einem interaktiven Layout manuell selektiert. Dabei wurden Titeleien, publizierte Bibliographien, besonders ungenügendes OCR und nur partiell oder gar nicht erhaltene Artikel entfernt. JSTOR und WOS-Quellen wurden vereint und überschneidende Artikel angeglichen, was zu einem finalen Datensatz von 288.546 Artikeln führte.
                
            
            
                Methode
                
                    Die Modellierung multilingualer Textcorpora stellt seit längerem ein Problem für zahlreiche Bereiche der Digital Humanities dar 
                    (Dombrowski 2020). Klassische Methoden, wie BOW-, Topic-, oder Wortvektormodelle stoßen hier an ihre Grenzen, da die von ihnen gelernten Repräsentationen hauptsächlich Unterschiede zwischen Sprachen als salienteste Muster erkennen, und das eigentliche übersprachliche Erkenntnisinteresse verdecken. Der aus diesen Problemen resultierende Fokus auf rein englischsprachiges Quellenmaterial ist unbefriedigend (Pitman und Taylor 2017; Galina Russell 2014). Multilinguale Sprachmodelle, wie z. B. xml-Roberta (Conneau u. a. 2020)
                     
                    sind zwar in der Lage, dieses Problem zu lösen, indem sie deckungsgleiche Vektorräume für verschiedene Sprachen bereitstellen. Ihre Anwendbarkeit auf spezifische Forschungskorpora ist allerdings begrenzt, da die notwendige Wissensrepräsentation über den spezifischen Textgehalt nicht gegeben ist. 
                    Das fine-tuning solcher Modelle auf den Forschungsdaten stellt hier allerdings eine Herausforderung dar, weil die dafür zur Verfügung stehenden Architekturen dazu tendieren, in multilingualen Trainingskorpora hauptsächlich Sprachunterschiede zu lernen und damit die Einbettungen ‚auseinanderzubrechen‘.
                
                
                    Ein kürzlich vorgeschlagener Lösungsansatz, nämlich die automatische Übersetzung des gesamten Textcorpus (vgl. Malaterre und Lareau 2022; siehe auch Böhm, Alexander u. a. 2022)
                     
                    ist vielversprechend für die Erforschung der thematischen Zusammensetzung von Korpora, aber 
                    ungeeignet
                     für Anwendungen in denen die unterschiedlichen 
                    Konnotationen
                     von Wörtern in unterschiedlichen Sprachen und Kontexten eine Rolle spielen. Weiterhin ist die automatisierte Überführung von anderen Sprachen in eine einzige Basissprache – Englisch – mit Blick auf den Wunsch nach einer Wertschätzung verschiedener Sprachkulturen nicht ideal.
                
                
                    
                        
                        Karte des verwendeten Datensatzes. Jeder der kleinen Datenpunkte entspricht einem von 288.546 Artikeln, angeordnet anhand der Cosinusähnlichkeit ihrer Textvektoren. Einzelne Cluster sind mit (aus Platzgründen) jeweils zwei zufällig ausgewählten Sprachen anhand von mit tfidf-ausgewählten Keywords gelabelt.
                    
                
                
                    In dieser Einreichung folgen wir dementsprechend einem alternativem Ansatz: Wir beginnen damit, zwei zur Erhebung von Textähnlichkeiten geeignete Sprachmodelle – ein 
                    englischsprachiges
                     (
                    paraphrase-distilroberta-base-v2
                    ) und ein multilingual vortrainiertes Modell (
                    xlm-roberta-base, beide bereitgestellt von 
                    Reimers und Gurevych 2019)
                     
                    auf trainings-samplen aus unserem Beispielkorpus feinzutunen. Für das englischsprachige Modell greifen wir dabei auf GPL 
                    (Wang u. a. 2022)
                     
                    zurück, das multilinguale Modell tunen wir mit TSDAE 
                    (Wang, Reimers, und Gurevych 2021)
                    , da der für GPL benötigte query-generator nur auf Englisch verfügbar ist. Danach verwenden wir den Ansatz von 
                    Reimers und Gurevych (2020
                    ) bei dem das englischsprachige Modell als ‘Lehrer’ verwendet wird, um mithilfe eines Korpus von Übersetzungen, die unterschiedlichen Sprachen in dem multilingualen Modell zur Deckung zu bringen. Wie Abb. 2 zeigt, gelingt das tatsächlich: Eine durch 
                    UMAP
                     
                    (McInnes, Healy, und Melville 2018)
                     
                    auf der Grundlage von Cosinus-Ähnlichkeiten zwischen Texteinbettungen erstellte Karte unseres Korpus weist keine separierten Cluster von Einzelsprachen auf. Gleichzeitig ist das TSDAE-pretraining über die Angleichung der Sprachen hinweg erhalten geblieben: In einem Philosophie-spezifischen triplet-evaluation task, bei dem das Modell mit drei Passagen aus der 
                    Stanford Encyclopedia of Philosophy 
                    konfontiert war, in welchem zwei aus dem selben Artikel, die dritte jedoch aus einem der (mit einem einfachen BOW-Modell ermittelten) zwanzig thematisch ähnlichsten Artikel stammte, verbesserte sich die Fähigkeit, die zusammengehörenden Artikel zu ermitteln, um sieben Prozentpunkte.
                
                Um von unserem Sprachmodell zu Antworten auf unsere Fragen nach der Struktur der analytisch-kontinentalen Kluft zu kommen, encodieren wir zuerst alle Texte in unserem Sample mit dem multilingualen Sprachmodell. 
                Die analytisch-Kontinentale Trennung wird in philosophiehistorischen Werken häufig über die Angabe von paradigmatischen ReferenzautorInnen eingeführt (e.g. "Frege", "Russel", "Moore", Quine, Strawson, … und "Hegel", "Husserl", "Heidegger","Adorno",...). Wir sammeln solche Listen in der Literatur und wählen die am häufigsten genannten Autoren aus. Dann wählen wir zufällig 2000 Beispielartikel aus, welche Autoren aus der einen, aber nicht der anderen Gruppe zitieren, also tendenziell eher aus der analytischen, oder kontinentalen Ecke kommen. Das ist unsere 'seed'-Stichprobe. 
                    Einem von Waller und Anderson (2021)
                     
                    inspirierten Verfahren für die Modellierung von Polarisierung in Online-communities folgend, bilden wir den durchschnittlichen Differenzvektor zwischen den Einbettungen dieser 'seed'-
                    A
                    rtikel. Anschließend suchen wir nach 500 Paaren von ähnlichen Artikeln, deren Vektordifferenz diesem Differenzvektor am ähnlichsten ist, d.h. Artikelpaaren, die ein ähnliches Thema behandeln, aber deren Grundeinstellung einmal analytisch, einmal kontinental ist. 
                    Ein solches Paar bilden beispielsweise 
                    der analytischere Text:
                     '¿Hay una Filosofia de la Ciencia en el ultimo Wittgenstein?' (Moulines 1989), und die kontinentaler gelagerte Besprechung: 'Von Umgangskörpern, Vertikalspannungen, Responsivität und Musikphilosophie: Ludwig Wittgenstein im Spiegel neuerer Literatur' (Kroß 2012). Auf diese Weise ‚bereinigen‘ wir die ursprünglichen Differenzvektoren von nur thematischen Ungleichgewichten. 
                
                Durch die Berechnung der Cosinus-Ähnlichkeit aller Artikelvektoren in dem Datensatz zu den kontinentalen und analytischen Artikeln in den ermittelten Artikelpaaren können wir so einen themenunabhängigen einzigen "Analytizität/Kontinentalität"-Score für jeden Artikel entlang der kontinentalen/analytischen Achse ableiten. Die Dichte-Verteilung aller Artikel auf diesem Score ist in Abb. 3.b dargestellt. 
                Für die Validierung dieser von dem Modell berechneten Scores, haben wir eine Web-Applikation entwickelt, in der NutzerInnen, in unserem Fall PhilosophInnen, den Titel eines Artikel aus unserem Datensatz angezeigt bekommen und entscheiden müssen, ob der Artikel aus der kontinentalen oder analytischen Philosophie stammt. Die Applikation ist sowohl auf Desktop-PCs als auch auf mobilen Endgeräten verfügbar. Die erstellte Applikation wird in den kommenden Monaten gezielt einem multilingualen Fachpublikum zugänglich gemacht werden, sodass die aus dem Sprachmodell generierten Scores empirisch validiert werden können.
                Um zu messen, wie sich die kontinentale/analytische Spaltung im Laufe der Zeit vergrößert/verkleinert hat, fitten wir eine Serie von verbundenen gaußschen Mischverteilungsmodellen auf den Datensatz. Unter der Annahme, dass der Datensatz tatsächlich durch die Wirkung zweier Prozesse, welche analytische und kontinentale Philosophie generieren, entstanden ist, geben uns diese Modelle die jeweilige zentrale Tendenz und Spannbreite dieser Prozesse an.
                
                    
                        
                        Verteilung von Artikeln entlang des analytisch-Kontinentalen-Gradienten. (a) zeigt die Entwicklung des Gradienten im Verlauf der Zeit. Zentrale Tendenzen und Dezile sind einer Serie von verbundenen zwei-Komponenten Gaußschen Mischmodellen entnommen. Im ersten Drittel wäre allerdings ein ein-Komponenten-Modell vorzuziehen. Vier einzelne Philosophen-Karrieren sind anhand der fortschreitenden zentralen Tendenz der Werte ihrer Artikel auf dem Gradienten eingetragen. Man beachte insbesondere die Karriere Rortys von einem ursprünglich analytischen Philosophen, zu einem der wirkungsvollsten Proponenten kontinentaler Autoren im angloamerikanischen Raum. (b) Zufällig ausgewählte Beispiel-Titel entlang des analytisch-kontinentalen Gradienten, nebst Dichte-Verteilung über das gesamte Sample.
                    
                
            
            
                Vorläufige Ergebnisse
                Die Ergebnisse dieser Modelle sind in Abb. 3.a wiedergegeben. Wir beobachten, dass sich die beiden Verteilungen bis in die späten 1940er Jahre nahezu parallel entwickeln – und in der Tat suggerieren die statistischen Kennzahlen der Modellwahl, dass eine einzige Gauß-Verteilung die Daten in diesem Bereich besser beschreiben würde. Von 1950 bis 1960 beobachten wir hingegen ein scharfes Ausschwenken der analytischen Verteilung, gemeinsam mit einer Verkleinerung der Breite der Verteilung – also eine Konzentration und Konsolidierung analytischer Tendenzen in unserem Korpus, verbunden mit einer asymmetrische Polarisierung, die bis heute weitestgehend konstant zu bestehen scheint.
            
            
                Diskussion
                Diese Ergebnisse stehen im scharfen Kontrast zu früheren monolingualen Zitations-Studien, die eine Isoliertheit kontinentaler Philosophie identifiziert hatten (Noichl 2021). Die Erweiterung des Datensatzes um mehrere Sprachen und die damit einhergehende methodologische Komplexität stellt also in jedem Fall eine notwendige Grundlage für weitere Untersuchungen dar. Dabei hat der verwendete Datensatz noch nicht alle Möglichkeiten zu multilingualer Erweiterung ausgeschöpft: Die reichhaltige spanischsprachige OpenAccess-Kultur hat in unserer Untersuchung zum Beispiel noch nicht ausreichend Eingang gefunden. Wenn für die gestellte Fragestellung auch nicht zwingend notwendig, wäre eine Erweiterung über den europäischen Sprachraum hinweg wünschenswert.
            
        