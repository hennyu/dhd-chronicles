
      Der aktuelle Diskurs in den Digital Humanities dreht sich
        vorwiegend um die Frage nach der Fruchtbarmachung digitaler Daten für
        wissenschaftliche Erkenntnisse. Dabei wird zunehmend die Maxime laut, dass
        geisteswissenschaftliche Kernmethoden informationstheoretische und –praktische
        Ansätze aufzunehmen hätten. Zu einseitig sei noch die Tätigkeit der Kunstgeschichte,
        nur digitale Quellen zu generieren und eine „digitized“ anstatt eine „digital art
        history“ (Drucker 2013) zu betreiben. Die für die Geisteswissenschaften typische
        hermeneutische Herangehensweise sollte beispielsweise Niederschlag in den
        Aushandlungsprozessen der „neuen“ Forschungsthemen der Digital Humanities finden
        (Gaehtgens 2013). In nahezu allen Bereichen – den Visualisierungen und
        Modellierungen sowie den zahlreichen Bild-Text-Datenbanken der bildbasierten
        Wissenschaften – lassen sich jedoch weder Ansätze einer selbstreflexiven Forschungs-
        und Vermittlungstätigkeit noch die Thematisierung prozessualer Vorgänge ausmachen.
        Gerade die Prozessualität von Forschung und Vermittlung in den Künsten, die
        historisch bedeutende Vorgänger aus dem analogen Bereich des Museums- und
        Publikationswesens hervorgebracht hat, müsste verstärkt Eingang in die
        Problematisierung von computergestützter Forschung in der Kunstwissenschaft
        finden.
        Mein Beitrag will mit historischen analogen und aktuellen
          digitalen Beispielen aus den objektbezogenen Bereichen der digitalen Kunstgeschichte
          einen Gegenentwurf zu „distant reading“ (Moretti) und „big data“ (beispielsweise Lev
          Manovichs vorgeschlagenen Data-Visualisierungen) vorlegen und ein besonderes
          Augenmerk auf die Vermittlung und Dokumentation gerade räumlicher Kunst
          (Ausstellungen, Installationen) werfen. Ein erster Teil thematisiert Projekte, die
          einen besonderen Bezug zwischen der historischen Gegenwart im Raum (Ausstellung) und
          deren Dokumentation (Ausstellungskatalog) entwickelt haben. Als besonderes Beispiel
          in diesem Kontext dient die erste monografische Ausstellung und Publikation des
          amerikanischen Künstlers Richard Tuttle, die Marcia Tucker 1975 für das Whitney
          Museum of American Art eingerichtet hat. Dieses Beispiel dient als Grundlage zu
          weiterführenden Überlegungen, wie rahmende Formate („framing devices“, Doulkaridou,
          2015) nicht nur Zugang zu Daten bieten, sondern auch deren Interpretation
          beeinflussen. Mögliche Strukturen der Vermittlung sind idealerweise durch eine
          Verräumlichung, wie sie bereits auch in Ausstellungen angelegt ist, geprägt. Dabei
          gilt es, nicht nur diese Strukturen auf ihre Nutzbarkeit in den Digital Humanities
          hin zu prüfen, sondern zugleich auch die gerne zur Wissensvermittlung herangezogenen
          Instrumente wie Modell, Modellierung oder Visualisierung kritisch zu befragen. Ein
          zentraler Diskussionspunkt ist beispielsweise die Frage nach dem Umgang historischer
          Lücken, die in Modellierungen oder Visualisierungen bisher keine allgemein
          eingeführten Formate gefunden haben, jedoch von großer wissenschaftlicher Relevanz
          sind. Gerade in bilderzeugenden Verfahren liegt der Schwerpunkt in der
          Visualisierung von vorhandenen Daten oder gar der Generierung neuer Daten, nicht
          aber in der Thematisierung der Datenlücken bzw. der prinzipiell fragmenthaften
          Quellenlage historischer Ereignisse, die sich an Dokumenten, Artefakten oder
          Kunstwerken festmachen lassen. An dieser grundlegenden Frage nach den Möglichkeiten
          digitaler Verfahren unterschieden sich die textbezogenen von den objektbezogenen
          Geisteswissenschaften in dem Sinne, dass bei den ersteren die Vorstellung einer
          potentiellen Fragmenthaftigkeit der zumindest gedruckten Literatur vernachlässigt
          wird.
          In einem zweiten Teil stellt der Vortrag drei unterschiedliche
            Ansätze der digitalen Kunstgeschichte vor, die sich einer kritischen Interpretation
            von bildbasierten Daten annähern: Das hypermediale Text-Bild-Archiv zu Anna
            Oppermanns Werken (Leuphana Universität Lüneburg; Wedemeyer; Warnke; Terstegge), das
            von mir entwickelte digitale Dokumentationsprojekt PTPROJECT.NET zum amerikanischen
            Künstler Paul Thek sowie die von Catherine Dossin konzipierte kritische Umsetzung
            eines Mapping-Projekts zur Rezeption amerikanischer Kunst im westlichen
            Nachkriegseuropa. Alle drei Projekte verbinden eine strukturelle Anlage, die über
            eine reine Bilddatenbank hinausgeht. Sie zeigen einen Umgang mit Quellenmaterial
            auf, das sich als „small data“ bezeichnen ließe und das Hinweise auf seine
            Entstehungsgeschichte bietet.
            Meine Überlegungen zielen folglich auf eine Umkehrung von den Verfahren der „big data“ zu einem Konzept der „small data“ im Kontext der kunsthistorischen Wissensbildung ab. Das Konzept der „small data“ fokussiert auf die kritische öffentliche Vermittlung von digitalen Daten, die gerade ihre Entstehungsgeschichte, Einzigartigkeit sowie ihre übersetzten inhärenten Qualitäten der abgebildeten künstlerischen Objekte und ihrer Verfahren in die Vermittlung miteinbeziehen und nicht durch einen distanzierten Blick auf die digitalisierte Masse ungreifbar machen wollen. Die Herausforderung dieses Ansatzes besteht darin, auf theoretischer Ebene einen Diskurs anzuregen, der sich mit der Problematik des „lückenhaften Quellennetzes“ (Reinhard Koselleck) in Bezug zu wissenschaftlichen Fragestellungen befasst, und der zugleich auf praktischer Ebene eine Umsetzung in veränderbaren, digitalen Wissensstrukturen ermöglicht. 
          